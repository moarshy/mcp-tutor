{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict, Any, Union, Set\n",
    "import hashlib\n",
    "import git\n",
    "import pickle\n",
    "import logging\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import dspy\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress litellm logs below WARNING\n",
    "logging.getLogger(\"litellm\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.configure(lm=dspy.LM(\"gemini/gemini-2.5-flash\", max_tokens=20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Models (same as before)\n",
    "class DocumentType(str, Enum):\n",
    "    TUTORIAL = \"tutorial\"\n",
    "    REFERENCE = \"reference\"\n",
    "    EXAMPLE = \"example\"\n",
    "    CONCEPT = \"concept\"\n",
    "\n",
    "class CodeBlock(BaseModel):\n",
    "    language: str\n",
    "    content: str\n",
    "    line_start: int\n",
    "    line_end: int\n",
    "\n",
    "class DocumentMetadata(BaseModel):\n",
    "    file_path: str\n",
    "    title: Optional[str] = None\n",
    "    headings: List[str] = Field(default_factory=list)\n",
    "    code_blocks: List[CodeBlock] = Field(default_factory=list)\n",
    "    links: List[str] = Field(default_factory=list)\n",
    "    word_count: int = 0\n",
    "\n",
    "class DocumentClassification(BaseModel):\n",
    "    file_path: str\n",
    "    doc_type: DocumentType\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "\n",
    "class DependencyRelation(BaseModel):\n",
    "    concept: str\n",
    "    prerequisites: List[str] = Field(default_factory=list)\n",
    "    confidence: float\n",
    "    evidence: str\n",
    "\n",
    "class AnalyzedDocument(BaseModel):\n",
    "    metadata: DocumentMetadata\n",
    "    classification: DocumentClassification\n",
    "    content: str\n",
    "    dependencies: List[DependencyRelation] = Field(default_factory=list)\n",
    "    summary: str = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated DSPy Signatures\n",
    "class ClassifyDocument(dspy.Signature):\n",
    "    \"\"\"Classify a technical document into one of four categories based on its content and structure.\"\"\"\n",
    "    \n",
    "    content: str = dspy.InputField(desc=\"The document content to classify\")\n",
    "    file_path: str = dspy.InputField(desc=\"The file path for context\")\n",
    "    headings: List[str] = dspy.InputField(desc=\"List of headings in the document\")\n",
    "    \n",
    "    classification: DocumentType = dspy.OutputField(desc=\"One of: tutorial, reference, example, concept\")\n",
    "    confidence: float = dspy.OutputField(desc=\"Confidence score between 0.0 and 1.0\")\n",
    "    reasoning: str = dspy.OutputField(desc=\"Brief explanation for the classification\")\n",
    "\n",
    "class ExtractDependencies(dspy.Signature):\n",
    "    \"\"\"Extract prerequisite concepts and dependencies from technical documentation.\"\"\"\n",
    "    \n",
    "    content: str = dspy.InputField(desc=\"The document content to analyze\")\n",
    "    title: str = dspy.InputField(desc=\"Document title or main concept\")\n",
    "    headings: List[str] = dspy.InputField(desc=\"List of headings in the document\")\n",
    "    \n",
    "    main_concepts: List[str] = dspy.OutputField(desc=\"List of main concepts covered in this document\")\n",
    "    prerequisites: List[str] = dspy.OutputField(desc=\"List of prerequisite concepts needed to understand this document\")\n",
    "    evidence: str = dspy.OutputField(desc=\"Text evidence supporting the identified dependencies\")\n",
    "\n",
    "class SummarizeDocument(dspy.Signature):\n",
    "    \"\"\"Create a concise summary of a technical document for contextual retrieval.\"\"\"\n",
    "    \n",
    "    content: str = dspy.InputField(desc=\"The full document content to summarize\")\n",
    "    title: str = dspy.InputField(desc=\"Document title\")\n",
    "    doc_type: str = dspy.InputField(desc=\"Document type (tutorial, reference, example, concept)\")\n",
    "    \n",
    "    summary: str = dspy.OutputField(desc=\"Concise 5-7 sentence summary providing context about this document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback parsers for string responses\n",
    "class FallbackParser:\n",
    "    @staticmethod\n",
    "    def parse_classification_response(response: str, file_path: str) -> DocumentClassification:\n",
    "        \"\"\"Parse string response for classification when structured output fails\"\"\"\n",
    "        \n",
    "        # Default values\n",
    "        doc_type = DocumentType.CONCEPT\n",
    "        confidence = 0.5\n",
    "        reasoning = \"Fallback classification\"\n",
    "        \n",
    "        try:\n",
    "            # Try to extract classification type\n",
    "            classification_patterns = [\n",
    "                r\"classification[:\\s]+(\\w+)\",\n",
    "                r\"type[:\\s]+(\\w+)\",\n",
    "                r\"category[:\\s]+(\\w+)\",\n",
    "                r\"(tutorial|reference|example|concept)\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in classification_patterns:\n",
    "                match = re.search(pattern, response.lower())\n",
    "                if match:\n",
    "                    found_type = match.group(1).lower()\n",
    "                    if found_type in [\"tutorial\", \"reference\", \"example\", \"concept\"]:\n",
    "                        doc_type = DocumentType(found_type)\n",
    "                        break\n",
    "            \n",
    "            # Try to extract confidence\n",
    "            confidence_patterns = [\n",
    "                r\"confidence[:\\s]+([0-9]*\\.?[0-9]+)\",\n",
    "                r\"score[:\\s]+([0-9]*\\.?[0-9]+)\",\n",
    "                r\"([0-9]*\\.?[0-9]+)\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in confidence_patterns:\n",
    "                match = re.search(pattern, response)\n",
    "                if match:\n",
    "                    try:\n",
    "                        found_confidence = float(match.group(1))\n",
    "                        if 0.0 <= found_confidence <= 1.0:\n",
    "                            confidence = found_confidence\n",
    "                            break\n",
    "                        elif found_confidence > 1.0:  # Handle percentage\n",
    "                            confidence = found_confidence / 100.0\n",
    "                            break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            # Extract reasoning (usually the whole response or a specific part)\n",
    "            reasoning_match = re.search(r\"reasoning[:\\s]+(.+)\", response, re.IGNORECASE | re.DOTALL)\n",
    "            if reasoning_match:\n",
    "                reasoning = reasoning_match.group(1).strip()\n",
    "            else:\n",
    "                reasoning = response[:200] + \"...\" if len(response) > 200 else response\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing classification response: {e}\")\n",
    "        \n",
    "        return DocumentClassification(\n",
    "            file_path=file_path,\n",
    "            doc_type=doc_type,\n",
    "            confidence=confidence,\n",
    "            reasoning=reasoning\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_dependencies_response(response: str) -> List[DependencyRelation]:\n",
    "        \"\"\"Parse string response for dependencies when structured output fails\"\"\"\n",
    "        \n",
    "        dependencies = []\n",
    "        \n",
    "        try:\n",
    "            # Try to extract main concepts\n",
    "            main_concepts = []\n",
    "            concepts_patterns = [\n",
    "                r\"main concepts?[:\\s]+(.+?)(?=prerequisites|evidence|$)\",\n",
    "                r\"concepts?[:\\s]+(.+?)(?=prerequisites|evidence|$)\",\n",
    "                r\"topics?[:\\s]+(.+?)(?=prerequisites|evidence|$)\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in concepts_patterns:\n",
    "                match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "                if match:\n",
    "                    concepts_text = match.group(1)\n",
    "                    # Split by common delimiters\n",
    "                    main_concepts = [\n",
    "                        c.strip().strip(',-.')\n",
    "                        for c in re.split(r'[,\\n\\-â€¢*]', concepts_text)\n",
    "                        if c.strip() and len(c.strip()) > 2\n",
    "                    ][:5]  # Limit to 5 concepts\n",
    "                    break\n",
    "            \n",
    "            # Try to extract prerequisites\n",
    "            prerequisites = []\n",
    "            prereq_patterns = [\n",
    "                r\"prerequisites?[:\\s]+(.+?)(?=evidence|main|$)\",\n",
    "                r\"requires?[:\\s]+(.+?)(?=evidence|main|$)\",\n",
    "                r\"dependencies?[:\\s]+(.+?)(?=evidence|main|$)\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in prereq_patterns:\n",
    "                match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "                if match:\n",
    "                    prereq_text = match.group(1)\n",
    "                    prerequisites = [\n",
    "                        p.strip().strip(',-.')\n",
    "                        for p in re.split(r'[,\\n\\-â€¢*]', prereq_text)\n",
    "                        if p.strip() and len(p.strip()) > 2\n",
    "                    ][:5]  # Limit to 5 prerequisites\n",
    "                    break\n",
    "            \n",
    "            # Extract evidence\n",
    "            evidence = \"Extracted from fallback parsing\"\n",
    "            evidence_patterns = [\n",
    "                r\"evidence[:\\s]+(.+)\",\n",
    "                r\"explanation[:\\s]+(.+)\",\n",
    "                r\"reasoning[:\\s]+(.+)\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in evidence_patterns:\n",
    "                match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "                if match:\n",
    "                    evidence = match.group(1).strip()[:500]  # Limit length\n",
    "                    break\n",
    "            \n",
    "            # Create dependency relations\n",
    "            if not main_concepts:\n",
    "                main_concepts = [\"Unknown concept\"]\n",
    "            \n",
    "            for concept in main_concepts:\n",
    "                dependencies.append(DependencyRelation(\n",
    "                    concept=concept,\n",
    "                    prerequisites=prerequisites,\n",
    "                    confidence=0.6,  # Lower confidence for fallback\n",
    "                    evidence=evidence\n",
    "                ))\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing dependencies response: {e}\")\n",
    "            # Return minimal dependency if parsing fails completely\n",
    "            dependencies = [DependencyRelation(\n",
    "                concept=\"Unknown concept\",\n",
    "                prerequisites=[],\n",
    "                confidence=0.3,\n",
    "                evidence=\"Fallback parsing failed\"\n",
    "            )]\n",
    "        \n",
    "        return dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_num_words(text: str, num_words: int = 3000):\n",
    "    words = text.split()\n",
    "    return ' '.join(words[:num_words])\n",
    "\n",
    "NUM_WORDS = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated DSPy Modules with fallback handling\n",
    "class DocumentClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classify = dspy.ChainOfThought(ClassifyDocument)\n",
    "    \n",
    "    def forward(self, content: str, file_path: str, headings: List[str]):\n",
    "        try:\n",
    "            result = self.classify(\n",
    "                content=content[:2000],  # Truncate for efficiency\n",
    "                file_path=file_path,\n",
    "                headings=headings\n",
    "            )\n",
    "            \n",
    "            # Check if we got structured output or string\n",
    "            if hasattr(result, 'classification') and hasattr(result, 'confidence') and hasattr(result, 'reasoning'):\n",
    "                # Structured output - validate and convert\n",
    "                doc_type_mapping = {\n",
    "                    \"tutorial\": DocumentType.TUTORIAL,\n",
    "                    \"reference\": DocumentType.REFERENCE, \n",
    "                    \"example\": DocumentType.EXAMPLE,\n",
    "                    \"concept\": DocumentType.CONCEPT\n",
    "                }\n",
    "                \n",
    "                # Handle both enum and string responses\n",
    "                if isinstance(result.classification, DocumentType):\n",
    "                    doc_type = result.classification\n",
    "                else:\n",
    "                    doc_type = doc_type_mapping.get(str(result.classification).lower(), DocumentType.CONCEPT)\n",
    "                \n",
    "                confidence = float(result.confidence) if result.confidence else 0.5\n",
    "                confidence = max(0.0, min(1.0, confidence))  # Clamp between 0 and 1\n",
    "                \n",
    "                return DocumentClassification(\n",
    "                    file_path=file_path,\n",
    "                    doc_type=doc_type,\n",
    "                    confidence=confidence,\n",
    "                    reasoning=str(result.reasoning)\n",
    "                )\n",
    "            else:\n",
    "                # String output - use fallback parser\n",
    "                logger.warning(f\"Got string response for classification, using fallback parser\")\n",
    "                response_str = str(result) if hasattr(result, '__str__') else str(result.classification) if hasattr(result, 'classification') else \"\"\n",
    "                return FallbackParser.parse_classification_response(response_str, file_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in document classification: {e}\")\n",
    "            # Return default classification\n",
    "            return DocumentClassification(\n",
    "                file_path=file_path,\n",
    "                doc_type=DocumentType.CONCEPT,\n",
    "                confidence=0.3,\n",
    "                reasoning=f\"Classification failed: {str(e)}\"\n",
    "            )\n",
    "\n",
    "class DependencyExtractor(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.extract = dspy.ChainOfThought(ExtractDependencies)\n",
    "    \n",
    "    def forward(self, content: str, title: str, headings: List[str]):\n",
    "        try:\n",
    "            result = self.extract(\n",
    "                content=content[:3000],  # Larger context for dependencies\n",
    "                title=title,\n",
    "                headings=headings\n",
    "            )\n",
    "            \n",
    "            # Check if we got structured output\n",
    "            if (hasattr(result, 'main_concepts') and \n",
    "                hasattr(result, 'prerequisites') and \n",
    "                hasattr(result, 'evidence')):\n",
    "                \n",
    "                # Structured output - process lists\n",
    "                main_concepts = result.main_concepts\n",
    "                prerequisites = result.prerequisites\n",
    "                evidence = str(result.evidence)\n",
    "                \n",
    "                # Handle both list and string responses for concepts/prerequisites\n",
    "                if isinstance(main_concepts, str):\n",
    "                    main_concepts = [c.strip() for c in main_concepts.split(\",\") if c.strip()]\n",
    "                if isinstance(prerequisites, str):\n",
    "                    prerequisites = [p.strip() for p in prerequisites.split(\",\") if p.strip()]\n",
    "                \n",
    "                dependencies = []\n",
    "                for concept in main_concepts:\n",
    "                    if concept.strip():  # Only add non-empty concepts\n",
    "                        dependencies.append(DependencyRelation(\n",
    "                            concept=concept.strip(),\n",
    "                            prerequisites=prerequisites,\n",
    "                            confidence=0.8,\n",
    "                            evidence=evidence\n",
    "                        ))\n",
    "                \n",
    "                return dependencies\n",
    "            else:\n",
    "                # String output - use fallback parser\n",
    "                logger.warning(f\"Got string response for dependencies, using fallback parser\")\n",
    "                response_str = str(result) if hasattr(result, '__str__') else \"\"\n",
    "                return FallbackParser.parse_dependencies_response(response_str)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in dependency extraction: {e}\")\n",
    "            # Return minimal dependency\n",
    "            return [DependencyRelation(\n",
    "                concept=title or \"Unknown\",\n",
    "                prerequisites=[],\n",
    "                confidence=0.3,\n",
    "                evidence=f\"Dependency extraction failed: {str(e)}\"\n",
    "            )]  \n",
    "        \n",
    "class DocumentSummarizer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.summarize = dspy.ChainOfThought(SummarizeDocument)\n",
    "    \n",
    "    def forward(self, content: str, title: str, doc_type: str):\n",
    "        result = self.summarize(\n",
    "            content=truncate_num_words(content, NUM_WORDS),\n",
    "            title=title,\n",
    "            doc_type=doc_type\n",
    "        )\n",
    "        return result.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RepoManager\n",
    "class RepoManager:\n",
    "    \"\"\"Handles repository cloning, caching, and file discovery\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: str):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def _get_repo_cache_path(self, repo_url: str) -> Path:\n",
    "        \"\"\"Generate cache path for repository\"\"\"\n",
    "        repo_hash = hashlib.md5(repo_url.encode()).hexdigest()\n",
    "        repo_name = urlparse(repo_url).path.strip('/').replace('/', '_')\n",
    "        return self.cache_dir / f\"{repo_name}_{repo_hash}\"\n",
    "    \n",
    "    def _get_analysis_cache_path(self, repo_url: str) -> Path:\n",
    "        \"\"\"Generate cache path for document analysis results\"\"\"\n",
    "        cache_path = self._get_repo_cache_path(repo_url)\n",
    "        return cache_path / \"analysis_results.pkl\"\n",
    "    \n",
    "    def clone_or_update_repo(self, repo_url: str, force_update: bool = False) -> Path:\n",
    "        \"\"\"Clone repository or update if it exists\"\"\"\n",
    "        repo_path = self._get_repo_cache_path(repo_url)\n",
    "        \n",
    "        if repo_path.exists() and not force_update:\n",
    "            logger.info(f\"Repository already cached at {repo_path}\")\n",
    "            try:\n",
    "                repo = git.Repo(repo_path)\n",
    "                repo.remotes.origin.pull()\n",
    "                logger.info(\"Updated repository with latest changes\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Warning: Could not update repository: {e}\")\n",
    "            return repo_path\n",
    "        \n",
    "        if repo_path.exists():\n",
    "            import shutil\n",
    "            shutil.rmtree(repo_path)\n",
    "            \n",
    "        logger.info(f\"Cloning repository to {repo_path}\")\n",
    "        git.Repo.clone_from(repo_url, repo_path)\n",
    "        return repo_path\n",
    "    \n",
    "    def find_documentation_files(self, repo_path: Path, include_folders: Optional[List[str]] = None) -> List[Path]:\n",
    "        \"\"\"Find all markdown files in repository, optionally filtered by folders\"\"\"\n",
    "        md_files = []\n",
    "        for ext in ['*.md', '*.mdx']:\n",
    "            md_files.extend(repo_path.rglob(ext))\n",
    "        \n",
    "        excluded_patterns = {\n",
    "            'node_modules', '.git', '__pycache__', '.pytest_cache',\n",
    "            'venv', 'env', '.venv', 'build', 'dist', 'tests', '.github'\n",
    "        }\n",
    "        \n",
    "        filtered_files = []\n",
    "        for file_path in md_files:\n",
    "            if not any(excluded in file_path.parts for excluded in excluded_patterns):\n",
    "                filtered_files.append(file_path)\n",
    "\n",
    "        # Remove common non-content files\n",
    "        filtered_files = [\n",
    "            file for file in filtered_files \n",
    "            if not file.name.lower().startswith(('license', 'contributing', 'code_of_conduct', 'security', 'patents', 'changelog'))\n",
    "        ]\n",
    "        \n",
    "        # Filter by include_folders if specified\n",
    "        if include_folders:\n",
    "            folder_filtered_files = []\n",
    "            for file_path in filtered_files:\n",
    "                rel_path = file_path.relative_to(repo_path)\n",
    "                rel_path_str = str(rel_path)\n",
    "                \n",
    "                for include_folder in include_folders:\n",
    "                    include_folder = include_folder.strip('/')\n",
    "                    \n",
    "                    if (rel_path_str.startswith(include_folder + '/') or \n",
    "                        rel_path_str.startswith(include_folder + '\\\\') or\n",
    "                        (include_folder == '.' and '/' not in rel_path_str and '\\\\' not in rel_path_str) or\n",
    "                        str(rel_path.parent) == include_folder or \n",
    "                        str(rel_path.parent).replace('\\\\', '/') == include_folder):\n",
    "                        folder_filtered_files.append(file_path)\n",
    "                        break\n",
    "            \n",
    "            filtered_files = folder_filtered_files\n",
    "            logger.info(f\"Filtered to {len(filtered_files)} files from specified folders: {include_folders}\")\n",
    "        \n",
    "        return sorted(filtered_files)\n",
    "    \n",
    "    def save_analysis_cache(self, analysis_results: List[AnalyzedDocument], repo_url: str):\n",
    "        \"\"\"Save document analysis results to cache\"\"\"\n",
    "        cache_path = self._get_analysis_cache_path(repo_url)\n",
    "        cache_path.parent.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Convert Pydantic models to dict for serialization\n",
    "        serializable_results = [doc.dict() for doc in analysis_results]\n",
    "        \n",
    "        with open(cache_path, 'wb') as f:\n",
    "            pickle.dump(serializable_results, f)\n",
    "        logger.info(f\"Saved analysis cache to {cache_path}\")\n",
    "    \n",
    "    def load_analysis_cache(self, repo_url: str) -> Optional[List[AnalyzedDocument]]:\n",
    "        \"\"\"Load document analysis results from cache\"\"\"\n",
    "        cache_path = self._get_analysis_cache_path(repo_url)\n",
    "        \n",
    "        if not cache_path.exists():\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                serialized_results = pickle.load(f)\n",
    "            \n",
    "            # Convert back to Pydantic models\n",
    "            results = [AnalyzedDocument(**doc_data) for doc_data in serialized_results]\n",
    "            logger.info(f\"Loaded analysis cache from {cache_path}\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading analysis cache: {e}\")\n",
    "            return None\n",
    "\n",
    "# DocAnalyzer (updated to work with new modules)\n",
    "class DocAnalyzer:\n",
    "    \"\"\"Analyzes technical documentation using DSPy modules\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classifier = DocumentClassifier()\n",
    "        self.dependency_extractor = DependencyExtractor()\n",
    "        self.summarizer = DocumentSummarizer()\n",
    "\n",
    "    def _extract_metadata(self, file_path: Path, content: str) -> DocumentMetadata:\n",
    "        \"\"\"Extract metadata from document content\"\"\"\n",
    "        \n",
    "        # Extract title (first H1 or filename)\n",
    "        title_match = re.search(r'^# (.+)$', content, re.MULTILINE)\n",
    "        title = title_match.group(1) if title_match else file_path.stem\n",
    "        \n",
    "        # Extract all headings\n",
    "        headings = re.findall(r'^#{1,6} (.+)$', content, re.MULTILINE)\n",
    "        \n",
    "        # Extract code blocks\n",
    "        code_blocks = []\n",
    "        code_pattern = r'```(\\w+)?\\n(.*?)\\n```'\n",
    "        for i, match in enumerate(re.finditer(code_pattern, content, re.DOTALL)):\n",
    "            language = match.group(1) or 'text'\n",
    "            code_content = match.group(2)\n",
    "            \n",
    "            # Calculate line numbers (approximate)\n",
    "            lines_before = content[:match.start()].count('\\n')\n",
    "            lines_in_block = code_content.count('\\n')\n",
    "            \n",
    "            code_blocks.append(CodeBlock(\n",
    "                language=language,\n",
    "                content=code_content,\n",
    "                line_start=lines_before + 1,\n",
    "                line_end=lines_before + lines_in_block + 1\n",
    "            ))\n",
    "        \n",
    "        # Extract links\n",
    "        links = re.findall(r'\\[([^\\]]+)\\]\\(([^)]+)\\)', content)\n",
    "        link_urls = [link[1] for link in links]\n",
    "        \n",
    "        # Word count\n",
    "        word_count = len(content.split())\n",
    "        \n",
    "        return DocumentMetadata(\n",
    "            file_path=str(file_path),\n",
    "            title=title,\n",
    "            headings=headings,\n",
    "            code_blocks=code_blocks,\n",
    "            links=link_urls,\n",
    "            word_count=word_count\n",
    "        )\n",
    "    \n",
    "    def analyze_document(self, file_path: Path, content: str) -> AnalyzedDocument:\n",
    "        \"\"\"Analyze a single document\"\"\"\n",
    "        \n",
    "        # Extract metadata\n",
    "        metadata = self._extract_metadata(file_path, content)\n",
    "        \n",
    "        # Classify document\n",
    "        classification = self.classifier(\n",
    "            content=content,\n",
    "            file_path=str(file_path),\n",
    "            headings=metadata.headings\n",
    "        )\n",
    "        \n",
    "        # Extract dependencies\n",
    "        dependencies = self.dependency_extractor(\n",
    "            content=content,\n",
    "            title=metadata.title or \"\",\n",
    "            headings=metadata.headings\n",
    "        )\n",
    "        \n",
    "        # Generate document summary for contextual retrieval\n",
    "        doc_summary = self.summarizer(\n",
    "            content=content,\n",
    "            title=metadata.title or file_path.stem,\n",
    "            doc_type=classification.doc_type.value\n",
    "        )\n",
    "        \n",
    "        return AnalyzedDocument(\n",
    "            metadata=metadata,\n",
    "            classification=classification,\n",
    "            content=content,\n",
    "            dependencies=dependencies,\n",
    "            summary=doc_summary\n",
    "        )\n",
    "    \n",
    "    def analyze_repository(self, file_paths: List[Path]) -> List[AnalyzedDocument]:\n",
    "        \"\"\"Analyze all documents in a repository\"\"\"\n",
    "        analyzed_docs = []\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                analyzed_doc = self.analyze_document(file_path, content)\n",
    "                analyzed_docs.append(analyzed_doc)\n",
    "                \n",
    "                logger.info(f\"Analyzed {file_path}: {analyzed_doc.classification.doc_type} (confidence: {analyzed_doc.classification.confidence:.2f})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error analyzing {file_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return analyzed_docs\n",
    "    \n",
    "    def get_classified_docs(self, analyzed_docs: List[AnalyzedDocument]) -> Dict[DocumentType, List[AnalyzedDocument]]:\n",
    "        \"\"\"Group analyzed documents by classification\"\"\"\n",
    "        classified = {doc_type: [] for doc_type in DocumentType}\n",
    "        \n",
    "        for doc in analyzed_docs:\n",
    "            classified[doc.classification.doc_type].append(doc)\n",
    "        \n",
    "        return classified\n",
    "    \n",
    "    def build_dependency_map(self, analyzed_docs: List[AnalyzedDocument]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Build a simple dependency map from analyzed documents\"\"\"\n",
    "        dependency_map = {}\n",
    "        \n",
    "        for doc in analyzed_docs:\n",
    "            for dep_relation in doc.dependencies:\n",
    "                if dep_relation.concept not in dependency_map:\n",
    "                    dependency_map[dep_relation.concept] = []\n",
    "                dependency_map[dep_relation.concept].extend(dep_relation.prerequisites)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        for concept in dependency_map:\n",
    "            dependency_map[concept] = list(set(dependency_map[concept]))\n",
    "        \n",
    "        return dependency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = \"https://github.com/modelcontextprotocol/docs\"\n",
    "repo_manager = RepoManager(cache_dir=\".cache\")\n",
    "doc_analyzer = DocAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Repository already cached at .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641\n",
      "INFO:__main__:Updated repository with latest changes\n",
      "INFO:__main__:Filtered to 14 files from specified folders: ['docs', 'tutorials', 'quickstart']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 documentation files\n"
     ]
    }
   ],
   "source": [
    "# Clone a repository\n",
    "repo_path = repo_manager.clone_or_update_repo(repo_url)\n",
    "\n",
    "# Find documentation files\n",
    "docs_files = repo_manager.find_documentation_files(\n",
    "    repo_path, \n",
    "    include_folders=[\"docs\", \"tutorials\", \"quickstart\"]\n",
    ")\n",
    "print(f\"Found {len(docs_files)} documentation files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/05 12:36:06 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/architecture.mdx: DocumentType.CONCEPT (confidence: 0.98)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/prompts.mdx: DocumentType.CONCEPT (confidence: 0.95)\n",
      "2025/07/05 12:36:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/resources.mdx: DocumentType.CONCEPT (confidence: 0.98)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/roots.mdx: DocumentType.CONCEPT (confidence: 0.98)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/sampling.mdx: DocumentType.REFERENCE (confidence: 0.95)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/tools.mdx: DocumentType.CONCEPT (confidence: 0.95)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/transports.mdx: DocumentType.CONCEPT (confidence: 0.95)\n",
      "2025/07/05 12:38:09 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/tools/debugging.mdx: DocumentType.TUTORIAL (confidence: 0.98)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/tools/inspector.mdx: DocumentType.TUTORIAL (confidence: 0.95)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/quickstart/client.mdx: DocumentType.TUTORIAL (confidence: 1.00)\n",
      "2025/07/05 12:38:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/quickstart/server.mdx: DocumentType.TUTORIAL (confidence: 1.00)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/quickstart/user.mdx: DocumentType.TUTORIAL (confidence: 1.00)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/tutorials/building-a-client-node.mdx: DocumentType.TUTORIAL (confidence: 1.00)\n",
      "INFO:__main__:Analyzed .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/tutorials/building-mcp-with-llms.mdx: DocumentType.TUTORIAL (confidence: 1.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed 14 documents\n"
     ]
    }
   ],
   "source": [
    "# Analyze documents\n",
    "analyzed_docs = doc_analyzer.analyze_repository(docs_files)\n",
    "print(f\"Analyzed {len(analyzed_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzed_docs[0].model_dump()['metadata']\n",
    "# analyzed_docs[0].model_dump()['classification']\n",
    "# analyzed_docs[0].model_dump()['dependencies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import dspy\n",
    "from pydantic import BaseModel, Field\n",
    "import openai\n",
    "from chromadb.errors import InvalidCollectionException  # Add this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentChunk(BaseModel):\n",
    "    \"\"\"Represents a chunk with contextual information\"\"\"\n",
    "    id: str\n",
    "    content: str\n",
    "    contextual_content: str  # Original content + document summary\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class QueryResult(BaseModel):\n",
    "    \"\"\"Result from vector database query\"\"\"\n",
    "    chunk: DocumentChunk\n",
    "    score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 3000\n",
    "CHUNK_OVERLAP = 100\n",
    "\n",
    "class VectorDB:\n",
    "    \"\"\"Simplified vector database with contextual retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 db_path: str = \"./vector_db\",\n",
    "                 collection_name: str = \"docs\",\n",
    "                 embedding_model: str = \"text-embedding-3-small\",\n",
    "                 chunk_size: int = 800,\n",
    "                 chunk_overlap: int = 100):\n",
    "        \n",
    "        self.db_path = Path(db_path)\n",
    "        self.db_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        \n",
    "        # Initialize ChromaDB\n",
    "        self.client = chromadb.PersistentClient(\n",
    "            path=str(self.db_path),\n",
    "            settings=Settings(anonymized_telemetry=False)\n",
    "        )\n",
    "        \n",
    "        self.collection_name = collection_name\n",
    "        self.embedding_model = embedding_model\n",
    "        \n",
    "        # Get or create collection - Fix the exception handling\n",
    "        try:\n",
    "            self.collection = self.client.get_collection(name=collection_name)\n",
    "            logger.info(f\"Loaded existing collection: {collection_name}\")\n",
    "        except InvalidCollectionException:  # Changed from ValueError\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=collection_name,\n",
    "                metadata={\"description\": \"Technical documentation with contextual retrieval\"}\n",
    "            )\n",
    "            logger.info(f\"Created new collection: {collection_name}\")\n",
    "    \n",
    "    def _generate_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate embeddings using OpenAI\"\"\"\n",
    "        try:\n",
    "            response = openai.embeddings.create(\n",
    "                model=self.embedding_model,\n",
    "                input=texts\n",
    "            )\n",
    "            return [data.embedding for data in response.data]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating embeddings: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _chunk_with_context(self, doc) -> List[DocumentChunk]:\n",
    "        \"\"\"Create contextual chunks from document\"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        # Simple word-based chunking\n",
    "        words = doc.content.split()\n",
    "        \n",
    "        # Create document context prefix\n",
    "        context_prefix = f\"Document: {doc.metadata.title or 'Untitled'} ({doc.classification.doc_type.value}). {doc.summary}\\n\\n\"\n",
    "        \n",
    "        # Extract and serialize complex metadata\n",
    "        main_concepts = [dep.concept for dep in doc.dependencies]\n",
    "        prerequisites = list(set([prereq for dep in doc.dependencies for prereq in dep.prerequisites]))\n",
    "        code_languages = list(set([block.language for block in doc.metadata.code_blocks]))\n",
    "        \n",
    "        # Serialize complex objects as JSON strings\n",
    "        headings_json = json.dumps(doc.metadata.headings)\n",
    "        code_blocks_json = json.dumps([block.model_dump() for block in doc.metadata.code_blocks])\n",
    "        dependencies_json = json.dumps(doc.model_dump()['dependencies'])\n",
    "        links_json = json.dumps(doc.metadata.links)\n",
    "        \n",
    "        for i in range(0, len(words), self.chunk_size - self.chunk_overlap):\n",
    "            chunk_words = words[i:i + self.chunk_size]\n",
    "            chunk_content = ' '.join(chunk_words)\n",
    "            \n",
    "            if len(chunk_content.strip()) < 100:  # Skip very short chunks\n",
    "                continue\n",
    "            \n",
    "            # Create contextual content (summary + chunk)\n",
    "            contextual_content = context_prefix + chunk_content\n",
    "            \n",
    "            chunk_id = f\"{hashlib.md5(doc.metadata.file_path.encode()).hexdigest()[:8]}_{i // (self.chunk_size - self.chunk_overlap)}\"\n",
    "            \n",
    "            # Detect if this specific chunk contains code\n",
    "            has_code = \"```\" in chunk_content or any(lang in chunk_content.lower() for lang in [\"python\", \"javascript\", \"java\", \"cpp\", \"rust\", \"go\"])\n",
    "            \n",
    "            # Find which heading section this chunk belongs to (approximate)\n",
    "            relevant_heading = \"\"\n",
    "            for heading in doc.metadata.headings:\n",
    "                if heading.lower() in chunk_content.lower():\n",
    "                    relevant_heading = heading\n",
    "                    break\n",
    "            \n",
    "            chunk = DocumentChunk(\n",
    "                id=chunk_id,\n",
    "                content=chunk_content,\n",
    "                contextual_content=contextual_content,\n",
    "                metadata={\n",
    "                    # Basic info\n",
    "                    \"file_path\": doc.metadata.file_path,\n",
    "                    \"title\": doc.metadata.title or \"\",\n",
    "                    \"doc_type\": doc.classification.doc_type.value,\n",
    "                    \"chunk_index\": i // (self.chunk_size - self.chunk_overlap),\n",
    "                    \n",
    "                    # Content analysis\n",
    "                    \"summary\": doc.summary,\n",
    "                    \"main_concepts\": \", \".join(main_concepts) if main_concepts else \"\",\n",
    "                    \"prerequisites\": \", \".join(prerequisites) if prerequisites else \"\",\n",
    "                    \n",
    "                    # Classification info\n",
    "                    \"classification_confidence\": float(doc.classification.confidence),\n",
    "                    \"classification_reasoning\": doc.classification.reasoning,\n",
    "                    \n",
    "                    # Technical metadata  \n",
    "                    \"code_languages\": \", \".join(code_languages) if code_languages else \"\",\n",
    "                    \"has_code\": has_code,\n",
    "                    \"relevant_heading\": relevant_heading,\n",
    "                    \n",
    "                    # Document structure\n",
    "                    \"total_headings\": len(doc.metadata.headings),\n",
    "                    \"total_code_blocks\": len(doc.metadata.code_blocks),\n",
    "                    \"total_links\": len(doc.metadata.links),\n",
    "                    \"doc_word_count\": doc.metadata.word_count,\n",
    "                    \n",
    "                    # Chunk position\n",
    "                    \"word_start\": i,\n",
    "                    \"word_end\": i + len(chunk_words),\n",
    "                    \"chunk_word_count\": len(chunk_words),\n",
    "                    \n",
    "                    # Rich structured data as JSON strings\n",
    "                    \"headings_json\": headings_json,\n",
    "                    \"code_blocks_json\": code_blocks_json,\n",
    "                    \"dependencies_json\": dependencies_json,\n",
    "                    \"links_json\": links_json,\n",
    "                    \n",
    "                    # Full document metadata as JSON (for advanced queries)\n",
    "                    \"full_metadata_json\": json.dumps(doc.metadata.model_dump()),\n",
    "                    \"full_classification_json\": json.dumps(doc.classification.model_dump())\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def add_documents(self, analyzed_docs: List, batch_size: int = 50):  # Remove type hint for now\n",
    "        \"\"\"Add documents to vector database with contextual retrieval\"\"\"\n",
    "        all_chunks = []\n",
    "        \n",
    "        # Create contextual chunks for all documents\n",
    "        for doc in analyzed_docs:\n",
    "            try:\n",
    "                chunks = self._chunk_with_context(doc)\n",
    "                all_chunks.extend(chunks)\n",
    "                logger.info(f\"Created {len(chunks)} contextual chunks for {doc.metadata.file_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing document {doc.metadata.file_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Add chunks to database in batches\n",
    "        for i in range(0, len(all_chunks), batch_size):\n",
    "            batch = all_chunks[i:i + batch_size]\n",
    "            \n",
    "            try:\n",
    "                # Use contextual content for embeddings\n",
    "                contextual_texts = [chunk.contextual_content for chunk in batch]\n",
    "                embeddings = self._generate_embeddings(contextual_texts)\n",
    "                \n",
    "                # Store original content but embed contextual content\n",
    "                ids = [chunk.id for chunk in batch]\n",
    "                documents = [chunk.content for chunk in batch]  # Store original content\n",
    "                metadatas = [chunk.metadata for chunk in batch]\n",
    "                \n",
    "                self.collection.add(\n",
    "                    ids=ids,\n",
    "                    embeddings=embeddings,\n",
    "                    documents=documents,\n",
    "                    metadatas=metadatas\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"Added batch {i//batch_size + 1}/{(len(all_chunks) + batch_size - 1)//batch_size}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error adding batch: {e}\")\n",
    "                continue\n",
    "        \n",
    "        logger.info(f\"Successfully added {len(all_chunks)} contextual chunks\")\n",
    "    \n",
    "    def query(self, \n",
    "            query_text: str, \n",
    "            n_results: int = 5,\n",
    "            doc_types: Optional[List[str]] = None,\n",
    "            concepts: Optional[List[str]] = None) -> List[QueryResult]:\n",
    "        \"\"\"Query the vector database\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Generate embedding for query\n",
    "            query_embedding = self._generate_embeddings([query_text])[0]\n",
    "            \n",
    "            # Build filter\n",
    "            where_clause = None\n",
    "            if doc_types:\n",
    "                where_clause = {\"doc_type\": {\"$in\": doc_types}}\n",
    "            \n",
    "            # Query\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=n_results,\n",
    "                where=where_clause\n",
    "            )\n",
    "            \n",
    "            # Convert to QueryResult objects\n",
    "            query_results = []\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                chunk = DocumentChunk(\n",
    "                    id=results['ids'][0][i],\n",
    "                    content=results['documents'][0][i],\n",
    "                    contextual_content=\"\",  # We don't store this\n",
    "                    metadata=results['metadatas'][0][i]\n",
    "                )\n",
    "                \n",
    "                # Convert distance to similarity score\n",
    "                distance = results['distances'][0][i]\n",
    "                score = 1 / (1 + distance)\n",
    "                \n",
    "                query_results.append(QueryResult(chunk=chunk, score=score))\n",
    "            \n",
    "            # Additional concept filtering if specified\n",
    "            if concepts:\n",
    "                filtered_results = []\n",
    "                for result in query_results:\n",
    "                    chunk_concepts_str = result.chunk.metadata.get('main_concepts', '')\n",
    "                    chunk_concepts = [c.strip() for c in chunk_concepts_str.split(',') if c.strip()]\n",
    "                    \n",
    "                    if any(concept.lower() in [c.lower() for c in chunk_concepts] for concept in concepts):\n",
    "                        filtered_results.append(result)\n",
    "                query_results = filtered_results\n",
    "            \n",
    "            return query_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error querying: {e}\")\n",
    "            return []\n",
    "\n",
    "    def query_advanced(self, \n",
    "                    query_text: str, \n",
    "                    n_results: int = 5,\n",
    "                    doc_types: Optional[List[str]] = None,\n",
    "                    code_languages: Optional[List[str]] = None,\n",
    "                    has_code: Optional[bool] = None,\n",
    "                    min_confidence: Optional[float] = None,\n",
    "                    concepts: Optional[List[str]] = None) -> List[QueryResult]:\n",
    "        \"\"\"Advanced query with multiple filters\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Generate embedding for query\n",
    "            query_embedding = self._generate_embeddings([query_text])[0]\n",
    "            \n",
    "            # Build complex where clause\n",
    "            where_conditions = []\n",
    "            \n",
    "            if doc_types:\n",
    "                where_conditions.append({\"doc_type\": {\"$in\": doc_types}})\n",
    "            \n",
    "            if has_code is not None:\n",
    "                where_conditions.append({\"has_code\": has_code})\n",
    "                \n",
    "            if min_confidence is not None:\n",
    "                where_conditions.append({\"classification_confidence\": {\"$gte\": min_confidence}})\n",
    "            \n",
    "            # Build final where clause\n",
    "            where_clause = None\n",
    "            if where_conditions:\n",
    "                if len(where_conditions) == 1:\n",
    "                    where_clause = where_conditions[0]\n",
    "                else:\n",
    "                    where_clause = {\"$and\": where_conditions}\n",
    "            \n",
    "            # Query\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=n_results,\n",
    "                where=where_clause\n",
    "            )\n",
    "            \n",
    "            # Convert to QueryResult objects\n",
    "            query_results = []\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                chunk = DocumentChunk(\n",
    "                    id=results['ids'][0][i],\n",
    "                    content=results['documents'][0][i],\n",
    "                    contextual_content=\"\",\n",
    "                    metadata=results['metadatas'][0][i]\n",
    "                )\n",
    "                \n",
    "                distance = results['distances'][0][i]\n",
    "                score = 1 / (1 + distance)\n",
    "                \n",
    "                query_results.append(QueryResult(chunk=chunk, score=score))\n",
    "            \n",
    "            # Post-filter for complex string matching\n",
    "            if code_languages or concepts:\n",
    "                filtered_results = []\n",
    "                for result in query_results:\n",
    "                    include = True\n",
    "                    \n",
    "                    # Filter by code languages\n",
    "                    if code_languages:\n",
    "                        chunk_languages = result.chunk.metadata.get('code_languages', '').split(', ')\n",
    "                        if not any(lang in chunk_languages for lang in code_languages):\n",
    "                            include = False\n",
    "                    \n",
    "                    # Filter by concepts\n",
    "                    if concepts:\n",
    "                        chunk_concepts = result.chunk.metadata.get('main_concepts', '').split(', ')\n",
    "                        if not any(concept.lower() in [c.lower() for c in chunk_concepts] for concept in concepts):\n",
    "                            include = False\n",
    "                    \n",
    "                    if include:\n",
    "                        filtered_results.append(result)\n",
    "                \n",
    "                query_results = filtered_results\n",
    "            \n",
    "            return query_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in advanced query: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get database statistics\"\"\"\n",
    "        try:\n",
    "            count = self.collection.count()\n",
    "            if count == 0:\n",
    "                return {\n",
    "                    \"total_chunks\": 0,\n",
    "                    \"doc_type_distribution\": {}\n",
    "                }\n",
    "                \n",
    "            sample = self.collection.get(limit=min(100, count))\n",
    "            \n",
    "            doc_types = {}\n",
    "            for metadata in sample['metadatas']:\n",
    "                doc_type = metadata.get('doc_type', 'unknown')\n",
    "                doc_types[doc_type] = doc_types.get(doc_type, 0) + 1\n",
    "            \n",
    "            return {\n",
    "                \"total_chunks\": count,\n",
    "                \"doc_type_distribution\": doc_types\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting stats: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def clear_collection(self):\n",
    "        \"\"\"Clear all data from the collection\"\"\"\n",
    "        try:\n",
    "            self.client.delete_collection(self.collection_name)\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"Technical documentation with contextual retrieval\"}\n",
    "            )\n",
    "            logger.info(f\"Cleared collection: {self.collection_name}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error clearing collection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDBManager:\n",
    "    \"\"\"Simple manager for vector database operations\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"./vector_db\"):\n",
    "        self.vector_db = VectorDB(db_path=db_path)\n",
    "    \n",
    "    def initialize_from_analysis(self, analyzed_docs: List):\n",
    "        \"\"\"Initialize database from analyzed documents\"\"\"\n",
    "        logger.info(\"Adding documents with contextual retrieval...\")\n",
    "        self.vector_db.add_documents(analyzed_docs)\n",
    "        return self.vector_db.get_stats()\n",
    "    \n",
    "    def search(self, query: str, n_results: int = 5, doc_types: List[str] = None) -> List[QueryResult]:\n",
    "        \"\"\"Basic search\"\"\"\n",
    "        return self.vector_db.query(query, n_results, doc_types)\n",
    "    \n",
    "    def search_by_heading(self, query: str, heading_keyword: str, n_results: int = 5) -> List[QueryResult]:\n",
    "        \"\"\"Search for content under specific headings\"\"\"\n",
    "        results = self.vector_db.query(query, n_results * 2)  # Get more results to filter\n",
    "        \n",
    "        filtered_results = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                headings = json.loads(result.chunk.metadata.get('headings_json', '[]'))\n",
    "                if any(heading_keyword.lower() in heading.lower() for heading in headings):\n",
    "                    filtered_results.append(result)\n",
    "                if len(filtered_results) >= n_results:\n",
    "                    break\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        return filtered_results\n",
    "    \n",
    "    def search_by_code_language(self, query: str, language: str, n_results: int = 5) -> List[QueryResult]:\n",
    "        \"\"\"Search for code examples in specific language\"\"\"\n",
    "        results = self.vector_db.query(query, n_results * 2)\n",
    "        \n",
    "        filtered_results = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                code_blocks = json.loads(result.chunk.metadata.get('code_blocks_json', '[]'))\n",
    "                if any(block.get('language', '').lower() == language.lower() for block in code_blocks):\n",
    "                    filtered_results.append(result)\n",
    "                if len(filtered_results) >= n_results:\n",
    "                    break\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        return filtered_results\n",
    "    \n",
    "    def search_by_dependency(self, query: str, required_concept: str, n_results: int = 5) -> List[QueryResult]:\n",
    "        \"\"\"Search for content that depends on a specific concept\"\"\"\n",
    "        results = self.vector_db.query(query, n_results * 2)\n",
    "        \n",
    "        filtered_results = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                dependencies = json.loads(result.chunk.metadata.get('dependencies_json', '[]'))\n",
    "                for dep in dependencies:\n",
    "                    if required_concept.lower() in dep.get('concept', '').lower():\n",
    "                        filtered_results.append(result)\n",
    "                        break\n",
    "                    if required_concept.lower() in [p.lower() for p in dep.get('prerequisites', [])]:\n",
    "                        filtered_results.append(result)\n",
    "                        break\n",
    "                if len(filtered_results) >= n_results:\n",
    "                    break\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        return filtered_results\n",
    "    \n",
    "    def get_chunk_analysis(self, chunk: DocumentChunk) -> Dict:\n",
    "        \"\"\"Extract rich analysis from a chunk's JSON metadata\"\"\"\n",
    "        try:\n",
    "            analysis = {\n",
    "                \"headings\": json.loads(chunk.metadata.get('headings_json', '[]')),\n",
    "                \"code_blocks\": json.loads(chunk.metadata.get('code_blocks_json', '[]')),\n",
    "                \"dependencies\": json.loads(chunk.metadata.get('dependencies_json', '[]')),\n",
    "                \"links\": json.loads(chunk.metadata.get('links_json', '[]')),\n",
    "                \"full_metadata\": json.loads(chunk.metadata.get('full_metadata_json', '{}')),\n",
    "                \"classification\": json.loads(chunk.metadata.get('full_classification_json', '{}'))\n",
    "            }\n",
    "            return analysis\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"Error parsing chunk metadata: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def find_learning_prerequisites(self, concept: str, n_results: int = 5) -> List[QueryResult]:\n",
    "        \"\"\"Find content that teaches prerequisites for a concept\"\"\"\n",
    "        results = self.vector_db.query(f\"learn {concept} prerequisites requirements\", n_results * 3)\n",
    "        \n",
    "        prerequisite_chunks = []\n",
    "        for result in results:\n",
    "            try:\n",
    "                dependencies = json.loads(result.chunk.metadata.get('dependencies_json', '[]'))\n",
    "                for dep in dependencies:\n",
    "                    if concept.lower() in dep.get('concept', '').lower():\n",
    "                        # This chunk teaches something that requires our concept\n",
    "                        for prereq in dep.get('prerequisites', []):\n",
    "                            prereq_results = self.vector_db.query(f\"{prereq} tutorial guide\", 3)\n",
    "                            prerequisite_chunks.extend(prereq_results)\n",
    "                        break\n",
    "                if len(prerequisite_chunks) >= n_results:\n",
    "                    break\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        return prerequisite_chunks[:n_results]\n",
    "    \n",
    "    def clear_database(self):\n",
    "        \"\"\"Clear the entire database\"\"\"\n",
    "        self.vector_db.clear_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded existing collection: docs\n",
      "INFO:__main__:Cleared collection: docs\n",
      "INFO:__main__:Adding documents with contextual retrieval...\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/architecture.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/prompts.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/resources.mdx\n",
      "INFO:__main__:Created 1 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/roots.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/sampling.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/tools.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/transports.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/tools/debugging.mdx\n",
      "INFO:__main__:Created 1 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/tools/inspector.mdx\n",
      "INFO:__main__:Created 8 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/quickstart/client.mdx\n",
      "INFO:__main__:Created 9 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/quickstart/server.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/quickstart/user.mdx\n",
      "INFO:__main__:Created 2 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/tutorials/building-a-client-node.mdx\n",
      "INFO:__main__:Created 1 contextual chunks for .cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/tutorials/building-mcp-with-llms.mdx\n",
      "INFO:__main__:Added batch 1/1\n",
      "INFO:__main__:Successfully added 38 contextual chunks\n"
     ]
    }
   ],
   "source": [
    "vector_db_manager = VectorDBManager(db_path=\"./vector_db\")\n",
    "vector_db_manager.clear_database()\n",
    "stats = vector_db_manager.initialize_from_analysis(analyzed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= vector_db_manager.search(query=\"tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk': {'id': 'cc0bfbf9_0',\n",
       "  'content': '--- title: \"Tools\" description: \"Enable LLMs to perform actions through your server\" --- Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients. Through tools, LLMs can interact with external systems, perform computations, and take actions in the real world. <Note> Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them (with a human in the loop to grant approval). </Note> ## Overview Tools in MCP allow servers to expose executable functions that can be invoked by clients and used by LLMs to perform actions. Key aspects of tools include: - **Discovery**: Clients can list available tools through the `tools/list` endpoint - **Invocation**: Tools are called using the `tools/call` endpoint, where servers perform the requested operation and return results - **Flexibility**: Tools can range from simple calculations to complex API interactions Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems. ## Tool definition structure Each tool is defined with the following structure: ```typescript { name: string; // Unique identifier for the tool description?: string; // Human-readable description inputSchema: { // JSON Schema for the tool\\'s parameters type: \"object\", properties: { ... } // Tool-specific parameters } } ``` ## Implementing tools Here\\'s an example of implementing a basic tool in an MCP server: <Tabs> <Tab title=\"TypeScript\"> ```typescript const server = new Server({ name: \"example-server\", version: \"1.0.0\" }, { capabilities: { tools: {} } }); // Define available tools server.setRequestHandler(ListToolsRequestSchema, async () => { return { tools: [{ name: \"calculate_sum\", description: \"Add two numbers together\", inputSchema: { type: \"object\", properties: { a: { type: \"number\" }, b: { type: \"number\" } }, required: [\"a\", \"b\"] } }] }; }); // Handle tool execution server.setRequestHandler(CallToolRequestSchema, async (request) => { if (request.params.name === \"calculate_sum\") { const { a, b } = request.params.arguments; return { content: [ { type: \"text\", text: String(a + b) } ] }; } throw new Error(\"Tool not found\"); }); ``` </Tab> <Tab title=\"Python\"> ```python app = Server(\"example-server\") @app.list_tools() async def list_tools() -> list[types.Tool]: return [ types.Tool( name=\"calculate_sum\", description=\"Add two numbers together\", inputSchema={ \"type\": \"object\", \"properties\": { \"a\": {\"type\": \"number\"}, \"b\": {\"type\": \"number\"} }, \"required\": [\"a\", \"b\"] } ) ] @app.call_tool() async def call_tool( name: str, arguments: dict ) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]: if name == \"calculate_sum\": a = arguments[\"a\"] b = arguments[\"b\"] result = a + b return [types.TextContent(type=\"text\", text=str(result))] raise ValueError(f\"Tool not found: {name}\") ``` </Tab> </Tabs> ## Example tool patterns Here are some examples of types of tools that a server could provide: ### System operations Tools that interact with the local system: ```typescript { name: \"execute_command\", description: \"Run a shell command\", inputSchema: { type: \"object\", properties: { command: { type: \"string\" }, args: { type: \"array\", items: { type: \"string\" } } } } } ``` ### API integrations Tools that wrap external APIs: ```typescript { name: \"github_create_issue\", description: \"Create a GitHub issue\", inputSchema: { type: \"object\", properties: { title: { type: \"string\" }, body: { type: \"string\" }, labels: { type: \"array\", items: { type: \"string\" } } } } } ``` ### Data processing Tools that transform or analyze data: ```typescript { name: \"analyze_csv\", description: \"Analyze a CSV file\", inputSchema: { type: \"object\", properties: { filepath: { type: \"string\" }, operations: { type: \"array\", items: { enum: [\"sum\", \"average\", \"count\"] } } } } } ``` ## Best practices When implementing tools: 1. Provide clear, descriptive names and descriptions 2. Use detailed JSON Schema definitions for parameters 3. Include examples in tool descriptions to demonstrate how the model should use them 4. Implement proper error handling and validation 5. Use progress reporting for long operations 6. Keep tool operations focused and atomic 7. Document expected return value structures 8. Implement proper timeouts 9. Consider rate limiting for resource-intensive operations 10. Log tool usage for debugging and monitoring ## Security considerations When exposing tools: ### Input validation - Validate all parameters against the schema - Sanitize file paths and system commands - Validate URLs and external identifiers - Check parameter sizes and ranges - Prevent command injection ### Access control - Implement authentication where needed - Use appropriate authorization checks - Audit tool usage - Rate limit requests - Monitor for abuse ### Error handling - Don\\'t expose internal errors to clients - Log security-relevant errors - Handle timeouts appropriately - Clean up resources after errors - Validate return values ## Tool discovery and updates MCP supports dynamic tool discovery: 1. Clients can list available tools at any time 2. Servers can notify clients when tools change using `notifications/tools/list_changed` 3. Tools can',\n",
       "  'contextual_content': '',\n",
       "  'metadata': {'chunk_index': 0,\n",
       "   'chunk_word_count': 800,\n",
       "   'classification_confidence': 0.95,\n",
       "   'classification_reasoning': 'The document primarily explains what \"Tools\" are within the Model Context Protocol, their purpose, structure, and key aspects. It defines a core component of the system, detailing its definition, how it works, and general implementation principles. While it includes a code snippet, it serves to illustrate the concept rather than provide a step-by-step guide or a comprehensive reference. The file path also indicates it\\'s a \"concept\" document.',\n",
       "   'code_blocks_json': '[{\"language\": \"typescript\", \"content\": \"{\\\\n  name: string;          // Unique identifier for the tool\\\\n  description?: string;  // Human-readable description\\\\n  inputSchema: {         // JSON Schema for the tool\\'s parameters\\\\n    type: \\\\\"object\\\\\",\\\\n    properties: { ... }  // Tool-specific parameters\\\\n  }\\\\n}\", \"line_start\": 26, \"line_end\": 33}, {\"language\": \"typescript\", \"content\": \"    const server = new Server({\\\\n      name: \\\\\"example-server\\\\\",\\\\n      version: \\\\\"1.0.0\\\\\"\\\\n    }, {\\\\n      capabilities: {\\\\n        tools: {}\\\\n      }\\\\n    });\\\\n\\\\n    // Define available tools\\\\n    server.setRequestHandler(ListToolsRequestSchema, async () => {\\\\n      return {\\\\n        tools: [{\\\\n          name: \\\\\"calculate_sum\\\\\",\\\\n          description: \\\\\"Add two numbers together\\\\\",\\\\n          inputSchema: {\\\\n            type: \\\\\"object\\\\\",\\\\n            properties: {\\\\n              a: { type: \\\\\"number\\\\\" },\\\\n              b: { type: \\\\\"number\\\\\" }\\\\n            },\\\\n            required: [\\\\\"a\\\\\", \\\\\"b\\\\\"]\\\\n          }\\\\n        }]\\\\n      };\\\\n    });\\\\n\\\\n    // Handle tool execution\\\\n    server.setRequestHandler(CallToolRequestSchema, async (request) => {\\\\n      if (request.params.name === \\\\\"calculate_sum\\\\\") {\\\\n        const { a, b } = request.params.arguments;\\\\n        return {\\\\n          content: [\\\\n            {\\\\n              type: \\\\\"text\\\\\",\\\\n              text: String(a + b)\\\\n            }\\\\n          ]\\\\n        };\\\\n      }\\\\n      throw new Error(\\\\\"Tool not found\\\\\");\\\\n    });\\\\n    ```\\\\n  </Tab>\\\\n  <Tab title=\\\\\"Python\\\\\">\\\\n    ```python\\\\n    app = Server(\\\\\"example-server\\\\\")\\\\n\\\\n    @app.list_tools()\\\\n    async def list_tools() -> list[types.Tool]:\\\\n        return [\\\\n            types.Tool(\\\\n                name=\\\\\"calculate_sum\\\\\",\\\\n                description=\\\\\"Add two numbers together\\\\\",\\\\n                inputSchema={\\\\n                    \\\\\"type\\\\\": \\\\\"object\\\\\",\\\\n                    \\\\\"properties\\\\\": {\\\\n                        \\\\\"a\\\\\": {\\\\\"type\\\\\": \\\\\"number\\\\\"},\\\\n                        \\\\\"b\\\\\": {\\\\\"type\\\\\": \\\\\"number\\\\\"}\\\\n                    },\\\\n                    \\\\\"required\\\\\": [\\\\\"a\\\\\", \\\\\"b\\\\\"]\\\\n                }\\\\n            )\\\\n        ]\\\\n\\\\n    @app.call_tool()\\\\n    async def call_tool(\\\\n        name: str,\\\\n        arguments: dict\\\\n    ) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\\\\n        if name == \\\\\"calculate_sum\\\\\":\\\\n            a = arguments[\\\\\"a\\\\\"]\\\\n            b = arguments[\\\\\"b\\\\\"]\\\\n            result = a + b\\\\n            return [types.TextContent(type=\\\\\"text\\\\\", text=str(result))]\\\\n        raise ValueError(f\\\\\"Tool not found: {name}\\\\\")\\\\n    ```\\\\n  </Tab>\\\\n</Tabs>\\\\n\\\\n## Example tool patterns\\\\n\\\\nHere are some examples of types of tools that a server could provide:\\\\n\\\\n### System operations\\\\n\\\\nTools that interact with the local system:\\\\n\", \"line_start\": 43, \"line_end\": 130}, {\"language\": \"text\", \"content\": \"\\\\n### API integrations\\\\n\\\\nTools that wrap external APIs:\\\\n\", \"line_start\": 144, \"line_end\": 148}, {\"language\": \"text\", \"content\": \"\\\\n### Data processing\\\\n\\\\nTools that transform or analyze data:\\\\n\", \"line_start\": 163, \"line_end\": 167}]',\n",
       "   'code_languages': 'text, typescript',\n",
       "   'dependencies_json': '[{\"concept\": \"Tools\", \"prerequisites\": [\"Model Context Protocol (MCP)\", \"LLMs (Large Language Models)\", \"Client-Server Architecture\", \"JSON Schema\", \"Resources (in MCP)\"], \"confidence\": 0.8, \"evidence\": \"\\\\\"Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients.\\\\\"\\\\n\\\\\"Enable LLMs to perform actions through your server\\\\\"\\\\n\\\\\"Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them\\\\\"\\\\n\\\\\"Clients can list available tools through the `tools/list` endpoint\\\\\"\\\\n\\\\\"Tools are called using the `tools/call` endpoint\\\\\"\\\\n\\\\\"inputSchema: { // JSON Schema for the tool\\'s parameters\\\\\"\\\\n\\\\\"Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems.\\\\\"\"}, {\"concept\": \"Model Context Protocol (MCP)\", \"prerequisites\": [\"Model Context Protocol (MCP)\", \"LLMs (Large Language Models)\", \"Client-Server Architecture\", \"JSON Schema\", \"Resources (in MCP)\"], \"confidence\": 0.8, \"evidence\": \"\\\\\"Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients.\\\\\"\\\\n\\\\\"Enable LLMs to perform actions through your server\\\\\"\\\\n\\\\\"Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them\\\\\"\\\\n\\\\\"Clients can list available tools through the `tools/list` endpoint\\\\\"\\\\n\\\\\"Tools are called using the `tools/call` endpoint\\\\\"\\\\n\\\\\"inputSchema: { // JSON Schema for the tool\\'s parameters\\\\\"\\\\n\\\\\"Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems.\\\\\"\"}, {\"concept\": \"Tool Definition Structure\", \"prerequisites\": [\"Model Context Protocol (MCP)\", \"LLMs (Large Language Models)\", \"Client-Server Architecture\", \"JSON Schema\", \"Resources (in MCP)\"], \"confidence\": 0.8, \"evidence\": \"\\\\\"Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients.\\\\\"\\\\n\\\\\"Enable LLMs to perform actions through your server\\\\\"\\\\n\\\\\"Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them\\\\\"\\\\n\\\\\"Clients can list available tools through the `tools/list` endpoint\\\\\"\\\\n\\\\\"Tools are called using the `tools/call` endpoint\\\\\"\\\\n\\\\\"inputSchema: { // JSON Schema for the tool\\'s parameters\\\\\"\\\\n\\\\\"Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems.\\\\\"\"}, {\"concept\": \"Tool Implementation\", \"prerequisites\": [\"Model Context Protocol (MCP)\", \"LLMs (Large Language Models)\", \"Client-Server Architecture\", \"JSON Schema\", \"Resources (in MCP)\"], \"confidence\": 0.8, \"evidence\": \"\\\\\"Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients.\\\\\"\\\\n\\\\\"Enable LLMs to perform actions through your server\\\\\"\\\\n\\\\\"Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them\\\\\"\\\\n\\\\\"Clients can list available tools through the `tools/list` endpoint\\\\\"\\\\n\\\\\"Tools are called using the `tools/call` endpoint\\\\\"\\\\n\\\\\"inputSchema: { // JSON Schema for the tool\\'s parameters\\\\\"\\\\n\\\\\"Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems.\\\\\"\"}, {\"concept\": \"Tool Discovery\", \"prerequisites\": [\"Model Context Protocol (MCP)\", \"LLMs (Large Language Models)\", \"Client-Server Architecture\", \"JSON Schema\", \"Resources (in MCP)\"], \"confidence\": 0.8, \"evidence\": \"\\\\\"Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients.\\\\\"\\\\n\\\\\"Enable LLMs to perform actions through your server\\\\\"\\\\n\\\\\"Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them\\\\\"\\\\n\\\\\"Clients can list available tools through the `tools/list` endpoint\\\\\"\\\\n\\\\\"Tools are called using the `tools/call` endpoint\\\\\"\\\\n\\\\\"inputSchema: { // JSON Schema for the tool\\'s parameters\\\\\"\\\\n\\\\\"Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems.\\\\\"\"}, {\"concept\": \"Tool Invocation\", \"prerequisites\": [\"Model Context Protocol (MCP)\", \"LLMs (Large Language Models)\", \"Client-Server Architecture\", \"JSON Schema\", \"Resources (in MCP)\"], \"confidence\": 0.8, \"evidence\": \"\\\\\"Tools are a powerful primitive in the Model Context Protocol (MCP) that enable servers to expose executable functionality to clients.\\\\\"\\\\n\\\\\"Enable LLMs to perform actions through your server\\\\\"\\\\n\\\\\"Tools are designed to be **model-controlled**, meaning that tools are exposed from servers to clients with the intention of the AI model being able to automatically invoke them\\\\\"\\\\n\\\\\"Clients can list available tools through the `tools/list` endpoint\\\\\"\\\\n\\\\\"Tools are called using the `tools/call` endpoint\\\\\"\\\\n\\\\\"inputSchema: { // JSON Schema for the tool\\'s parameters\\\\\"\\\\n\\\\\"Like [resources](/docs/concepts/resources), tools are identified by unique names and can include descriptions to guide their usage. However, unlike resources, tools represent dynamic operations that can modify state or interact with external systems.\\\\\"\"}]',\n",
       "   'doc_type': 'concept',\n",
       "   'doc_word_count': 1066,\n",
       "   'file_path': '.cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/tools.mdx',\n",
       "   'full_classification_json': '{\"file_path\": \".cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/tools.mdx\", \"doc_type\": \"concept\", \"confidence\": 0.95, \"reasoning\": \"The document primarily explains what \\\\\"Tools\\\\\" are within the Model Context Protocol, their purpose, structure, and key aspects. It defines a core component of the system, detailing its definition, how it works, and general implementation principles. While it includes a code snippet, it serves to illustrate the concept rather than provide a step-by-step guide or a comprehensive reference. The file path also indicates it\\'s a \\\\\"concept\\\\\" document.\"}',\n",
       "   'full_metadata_json': '{\"file_path\": \".cache/modelcontextprotocol_docs_9b06b34c6341a02b233055dc593dd641/docs/concepts/tools.mdx\", \"title\": \"tools\", \"headings\": [\"Overview\", \"Tool definition structure\", \"Implementing tools\", \"Example tool patterns\", \"System operations\", \"API integrations\", \"Data processing\", \"Best practices\", \"Security considerations\", \"Input validation\", \"Access control\", \"Error handling\", \"Tool discovery and updates\", \"Error handling\", \"Testing tools\"], \"code_blocks\": [{\"language\": \"typescript\", \"content\": \"{\\\\n  name: string;          // Unique identifier for the tool\\\\n  description?: string;  // Human-readable description\\\\n  inputSchema: {         // JSON Schema for the tool\\'s parameters\\\\n    type: \\\\\"object\\\\\",\\\\n    properties: { ... }  // Tool-specific parameters\\\\n  }\\\\n}\", \"line_start\": 26, \"line_end\": 33}, {\"language\": \"typescript\", \"content\": \"    const server = new Server({\\\\n      name: \\\\\"example-server\\\\\",\\\\n      version: \\\\\"1.0.0\\\\\"\\\\n    }, {\\\\n      capabilities: {\\\\n        tools: {}\\\\n      }\\\\n    });\\\\n\\\\n    // Define available tools\\\\n    server.setRequestHandler(ListToolsRequestSchema, async () => {\\\\n      return {\\\\n        tools: [{\\\\n          name: \\\\\"calculate_sum\\\\\",\\\\n          description: \\\\\"Add two numbers together\\\\\",\\\\n          inputSchema: {\\\\n            type: \\\\\"object\\\\\",\\\\n            properties: {\\\\n              a: { type: \\\\\"number\\\\\" },\\\\n              b: { type: \\\\\"number\\\\\" }\\\\n            },\\\\n            required: [\\\\\"a\\\\\", \\\\\"b\\\\\"]\\\\n          }\\\\n        }]\\\\n      };\\\\n    });\\\\n\\\\n    // Handle tool execution\\\\n    server.setRequestHandler(CallToolRequestSchema, async (request) => {\\\\n      if (request.params.name === \\\\\"calculate_sum\\\\\") {\\\\n        const { a, b } = request.params.arguments;\\\\n        return {\\\\n          content: [\\\\n            {\\\\n              type: \\\\\"text\\\\\",\\\\n              text: String(a + b)\\\\n            }\\\\n          ]\\\\n        };\\\\n      }\\\\n      throw new Error(\\\\\"Tool not found\\\\\");\\\\n    });\\\\n    ```\\\\n  </Tab>\\\\n  <Tab title=\\\\\"Python\\\\\">\\\\n    ```python\\\\n    app = Server(\\\\\"example-server\\\\\")\\\\n\\\\n    @app.list_tools()\\\\n    async def list_tools() -> list[types.Tool]:\\\\n        return [\\\\n            types.Tool(\\\\n                name=\\\\\"calculate_sum\\\\\",\\\\n                description=\\\\\"Add two numbers together\\\\\",\\\\n                inputSchema={\\\\n                    \\\\\"type\\\\\": \\\\\"object\\\\\",\\\\n                    \\\\\"properties\\\\\": {\\\\n                        \\\\\"a\\\\\": {\\\\\"type\\\\\": \\\\\"number\\\\\"},\\\\n                        \\\\\"b\\\\\": {\\\\\"type\\\\\": \\\\\"number\\\\\"}\\\\n                    },\\\\n                    \\\\\"required\\\\\": [\\\\\"a\\\\\", \\\\\"b\\\\\"]\\\\n                }\\\\n            )\\\\n        ]\\\\n\\\\n    @app.call_tool()\\\\n    async def call_tool(\\\\n        name: str,\\\\n        arguments: dict\\\\n    ) -> list[types.TextContent | types.ImageContent | types.EmbeddedResource]:\\\\n        if name == \\\\\"calculate_sum\\\\\":\\\\n            a = arguments[\\\\\"a\\\\\"]\\\\n            b = arguments[\\\\\"b\\\\\"]\\\\n            result = a + b\\\\n            return [types.TextContent(type=\\\\\"text\\\\\", text=str(result))]\\\\n        raise ValueError(f\\\\\"Tool not found: {name}\\\\\")\\\\n    ```\\\\n  </Tab>\\\\n</Tabs>\\\\n\\\\n## Example tool patterns\\\\n\\\\nHere are some examples of types of tools that a server could provide:\\\\n\\\\n### System operations\\\\n\\\\nTools that interact with the local system:\\\\n\", \"line_start\": 43, \"line_end\": 130}, {\"language\": \"text\", \"content\": \"\\\\n### API integrations\\\\n\\\\nTools that wrap external APIs:\\\\n\", \"line_start\": 144, \"line_end\": 148}, {\"language\": \"text\", \"content\": \"\\\\n### Data processing\\\\n\\\\nTools that transform or analyze data:\\\\n\", \"line_start\": 163, \"line_end\": 167}], \"links\": [\"/docs/concepts/resources\"], \"word_count\": 1066}',\n",
       "   'has_code': True,\n",
       "   'headings_json': '[\"Overview\", \"Tool definition structure\", \"Implementing tools\", \"Example tool patterns\", \"System operations\", \"API integrations\", \"Data processing\", \"Best practices\", \"Security considerations\", \"Input validation\", \"Access control\", \"Error handling\", \"Tool discovery and updates\", \"Error handling\", \"Testing tools\"]',\n",
       "   'links_json': '[\"/docs/concepts/resources\"]',\n",
       "   'main_concepts': 'Tools, Model Context Protocol (MCP), Tool Definition Structure, Tool Implementation, Tool Discovery, Tool Invocation',\n",
       "   'prerequisites': 'Model Context Protocol (MCP), Resources (in MCP), JSON Schema, Client-Server Architecture, LLMs (Large Language Models)',\n",
       "   'relevant_heading': 'Overview',\n",
       "   'summary': 'Tools in the Model Context Protocol (MCP) are a powerful primitive enabling servers to expose executable functionality to clients, allowing Large Language Models (LLMs) to interact with external systems, perform computations, and take real-world actions. Designed to be model-controlled with human approval, these tools are discovered via a `tools/list` endpoint and invoked through `tools/call`, offering flexibility for diverse operations like system commands, API integrations, or data processing. Each tool is defined by a unique name, description, and a JSON Schema for its input parameters. The document outlines implementation examples, best practices for clear definitions and robust error handling, and critical security considerations such as input validation and access control. Importantly, tool errors are reported within the result object, allowing the LLM to interpret and potentially address them.',\n",
       "   'title': 'tools',\n",
       "   'total_code_blocks': 4,\n",
       "   'total_headings': 15,\n",
       "   'total_links': 1,\n",
       "   'word_end': 800,\n",
       "   'word_start': 0}},\n",
       " 'score': 0.4437695107803981}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic BaseModels\n",
    "class LearningModule(BaseModel):\n",
    "    \"\"\"A learning module covering a specific topic\"\"\"\n",
    "    title: str\n",
    "    tutorial_content: List[str] = Field(default_factory=list)  # chunk IDs\n",
    "    concept_content: List[str] = Field(default_factory=list)   # chunk IDs  \n",
    "    example_content: List[str] = Field(default_factory=list)   # chunk IDs\n",
    "    reference_content: List[str] = Field(default_factory=list) # chunk IDs\n",
    "    estimated_time: int = 0  # minutes\n",
    "    content_summary: str = \"\"\n",
    "\n",
    "class LearningPath(BaseModel):\n",
    "    \"\"\"Complete learning path with ordered modules\"\"\"\n",
    "    modules: List[LearningModule]\n",
    "    difficulty_level: str = \"intermediate\"\n",
    "    total_time: int = 0\n",
    "    module_count: int = 0\n",
    "    discovery_reasoning: str = \"\"\n",
    "    ordering_reasoning: str = \"\"\n",
    "    content_gaps: List[str] = Field(default_factory=list)\n",
    "\n",
    "class ContentSummary(BaseModel):\n",
    "    \"\"\"Summary of available documentation content\"\"\"\n",
    "    total_docs: int\n",
    "    doc_types: Dict[str, int]  # {\"tutorial\": 5, \"concept\": 10, ...}\n",
    "    main_topics: List[str]\n",
    "    sample_titles: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy Signatures\n",
    "class DiscoverModules(dspy.Signature):\n",
    "    \"\"\"Analyze available documentation and suggest logical learning modules.\"\"\"\n",
    "    \n",
    "    content_summary: str = dspy.InputField(desc=\"Summary of available documentation topics and types\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty: beginner, intermediate, or advanced\") \n",
    "    user_modules: str = dspy.InputField(desc=\"User-provided modules if any, or 'none'\")\n",
    "    \n",
    "    modules: List[str] = dspy.OutputField(desc=\"List of 3-8 logical learning modules\")\n",
    "    reasoning: str = dspy.OutputField(desc=\"Brief explanation of module choices and structure\")\n",
    "\n",
    "class OrderModules(dspy.Signature):\n",
    "    \"\"\"Order learning modules in optimal pedagogical sequence.\"\"\"\n",
    "    \n",
    "    modules: List[str] = dspy.InputField(desc=\"List of learning modules to order\")\n",
    "    content_overview: str = dspy.InputField(desc=\"Overview of available content\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty level\")\n",
    "    \n",
    "    ordered_modules: List[str] = dspy.OutputField(desc=\"Modules ordered from foundational to advanced\")\n",
    "    reasoning: str = dspy.OutputField(desc=\"Explanation of the ordering logic and prerequisites\")\n",
    "\n",
    "\n",
    "class GenerateSearchQueries(dspy.Signature):\n",
    "    \"\"\"Generate optimal search queries for finding content related to a learning module.\"\"\"\n",
    "    \n",
    "    module_title: str = dspy.InputField(desc=\"The learning module title to search for\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty: beginner, intermediate, or advanced\")\n",
    "    doc_type: str = dspy.InputField(desc=\"Document type to search: tutorial, concept, example, or reference\")\n",
    "    available_content: str = dspy.InputField(desc=\"Brief overview of what content is available\")\n",
    "    \n",
    "    search_queries: List[str] = dspy.OutputField(desc=\"List of 3-5 specific search queries optimized for this module and difficulty\")\n",
    "    reasoning: str = dspy.OutputField(desc=\"Brief explanation of the search strategy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FallbackParser:\n",
    "    @staticmethod\n",
    "    def parse_modules_response(response: str) -> tuple[List[str], str]:\n",
    "        \"\"\"Parse module list from string response\"\"\"\n",
    "        modules = []\n",
    "        reasoning = \"\"\n",
    "        \n",
    "        try:\n",
    "            # Look for numbered lists or bullet points\n",
    "            module_patterns = [\n",
    "                r'\\d+\\.\\s*([^\\n]+)',  # 1. Module Name\n",
    "                r'[-â€¢*]\\s*([^\\n]+)',  # - Module Name  \n",
    "                r'^([A-Z][^\\n:]+)$'   # Plain module names\n",
    "            ]\n",
    "            \n",
    "            for pattern in module_patterns:\n",
    "                matches = re.findall(pattern, response, re.MULTILINE)\n",
    "                if matches:\n",
    "                    modules = [m.strip().strip('.,') for m in matches if len(m.strip()) > 3][:8]\n",
    "                    break\n",
    "            \n",
    "            # Extract reasoning\n",
    "            reasoning_patterns = [\n",
    "                r'reasoning[:\\s]+(.+)',\n",
    "                r'explanation[:\\s]+(.+)',\n",
    "                r'rationale[:\\s]+(.+)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in reasoning_patterns:\n",
    "                match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
    "                if match:\n",
    "                    reasoning = match.group(1).strip()[:300]\n",
    "                    break\n",
    "            \n",
    "            if not reasoning:\n",
    "                reasoning = \"Modules extracted from LLM response\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing modules response: {e}\")\n",
    "            modules = [\"Introduction\", \"Core Concepts\", \"Implementation\", \"Advanced Topics\"]\n",
    "            reasoning = \"Fallback module structure used\"\n",
    "        \n",
    "        return modules, reasoning\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_ordering_response(response: str, original_modules: List[str]) -> tuple[List[str], str]:\n",
    "        \"\"\"Parse ordered modules from string response\"\"\"\n",
    "        ordered_modules = []\n",
    "        reasoning = \"\"\n",
    "        \n",
    "        try:\n",
    "            # Look for ordered lists\n",
    "            order_patterns = [\n",
    "                r'\\d+\\.\\s*([^\\n]+)',\n",
    "                r'[-â€¢*]\\s*([^\\n]+)',\n",
    "            ]\n",
    "            \n",
    "            for pattern in order_patterns:\n",
    "                matches = re.findall(pattern, response, re.MULTILINE)\n",
    "                if matches:\n",
    "                    # Try to match with original modules\n",
    "                    for match in matches:\n",
    "                        match_clean = match.strip().strip('.,')\n",
    "                        for orig_module in original_modules:\n",
    "                            if (orig_module.lower() in match_clean.lower() or \n",
    "                                match_clean.lower() in orig_module.lower()):\n",
    "                                if orig_module not in ordered_modules:\n",
    "                                    ordered_modules.append(orig_module)\n",
    "                                break\n",
    "                    break\n",
    "            \n",
    "            # If no good matches, return original order\n",
    "            if len(ordered_modules) < len(original_modules) * 0.8:\n",
    "                ordered_modules = original_modules\n",
    "            \n",
    "            # Extract reasoning\n",
    "            reasoning_match = re.search(r'reasoning[:\\s]+(.+)', response, re.IGNORECASE | re.DOTALL)\n",
    "            reasoning = reasoning_match.group(1).strip()[:300] if reasoning_match else \"Module ordering applied\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing ordering response: {e}\")\n",
    "            ordered_modules = original_modules\n",
    "            reasoning = \"Original module order preserved\"\n",
    "        \n",
    "        return ordered_modules, reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleDiscoverer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.discover = dspy.ChainOfThought(DiscoverModules)\n",
    "    \n",
    "    def forward(self, content_summary: str, difficulty_level: str, user_modules: Optional[List[str]] = None):\n",
    "        try:\n",
    "            user_modules_str = \", \".join(user_modules) if user_modules else \"none\"\n",
    "            \n",
    "            result = self.discover(\n",
    "                content_summary=content_summary,\n",
    "                difficulty_level=difficulty_level,\n",
    "                user_modules=user_modules_str\n",
    "            )\n",
    "            \n",
    "            # Check if we got structured output\n",
    "            if hasattr(result, 'modules') and hasattr(result, 'reasoning'):\n",
    "                modules = result.modules\n",
    "                reasoning = str(result.reasoning)\n",
    "                \n",
    "                # Handle case where modules is a string\n",
    "                if isinstance(modules, str):\n",
    "                    modules, reasoning = FallbackParser.parse_modules_response(modules)\n",
    "                \n",
    "                return modules, reasoning\n",
    "            else:\n",
    "                # String response - use fallback\n",
    "                response_str = str(result)\n",
    "                return FallbackParser.parse_modules_response(response_str)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in module discovery: {e}\")\n",
    "            return [\"Introduction\", \"Core Concepts\", \"Implementation\"], \"Fallback modules used due to error\"\n",
    "\n",
    "class ModuleOrderer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.order = dspy.ChainOfThought(OrderModules)\n",
    "    \n",
    "    def forward(self, modules: List[str], content_overview: str, difficulty_level: str):\n",
    "        try:\n",
    "            result = self.order(\n",
    "                modules=modules,\n",
    "                content_overview=content_overview,\n",
    "                difficulty_level=difficulty_level\n",
    "            )\n",
    "            \n",
    "            # Check if we got structured output\n",
    "            if hasattr(result, 'ordered_modules') and hasattr(result, 'reasoning'):\n",
    "                ordered_modules = result.ordered_modules\n",
    "                reasoning = str(result.reasoning)\n",
    "                \n",
    "                # Handle case where ordered_modules is a string\n",
    "                if isinstance(ordered_modules, str):\n",
    "                    ordered_modules, reasoning = FallbackParser.parse_ordering_response(ordered_modules, modules)\n",
    "                \n",
    "                return ordered_modules, reasoning\n",
    "            else:\n",
    "                # String response - use fallback\n",
    "                response_str = str(result)\n",
    "                return FallbackParser.parse_ordering_response(response_str, modules)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in module ordering: {e}\")\n",
    "            return modules, \"Original order preserved due to error\"\n",
    "\n",
    "class QueryGenerator(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate = dspy.ChainOfThought(GenerateSearchQueries)\n",
    "    \n",
    "    def forward(self, module_title: str, difficulty_level: str, doc_type: str, available_content: str):\n",
    "        try:\n",
    "            result = self.generate(\n",
    "                module_title=module_title,\n",
    "                difficulty_level=difficulty_level,\n",
    "                doc_type=doc_type,\n",
    "                available_content=available_content\n",
    "            )\n",
    "            \n",
    "            # Check if we got structured output\n",
    "            if hasattr(result, 'search_queries') and hasattr(result, 'reasoning'):\n",
    "                queries = result.search_queries\n",
    "                reasoning = str(result.reasoning)\n",
    "                \n",
    "                # Handle case where queries is a string\n",
    "                if isinstance(queries, str):\n",
    "                    queries = self._parse_queries_from_string(queries)\n",
    "                \n",
    "                return queries, reasoning\n",
    "            else:\n",
    "                # String response - parse it\n",
    "                response_str = str(result)\n",
    "                queries = self._parse_queries_from_string(response_str)\n",
    "                return queries, \"Generated from LLM response\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating search queries: {e}\")\n",
    "            # Fallback to simple queries\n",
    "            return [f\"{module_title} {doc_type}\", f\"how to {module_title}\"], \"Fallback queries used\"\n",
    "    \n",
    "    def _parse_queries_from_string(self, response: str) -> List[str]:\n",
    "        \"\"\"Parse search queries from string response\"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        try:\n",
    "            # Look for numbered lists, bullet points, or quoted strings\n",
    "            patterns = [\n",
    "                r'\\d+\\.\\s*[\"\\']?([^\"\\'\\n]+)[\"\\']?',  # 1. \"query\"\n",
    "                r'[-â€¢*]\\s*[\"\\']?([^\"\\'\\n]+)[\"\\']?',  # - \"query\"\n",
    "                r'\"([^\"]+)\"',  # \"quoted strings\"\n",
    "                r\"'([^']+)'\",  # 'quoted strings'\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, response)\n",
    "                if matches:\n",
    "                    queries = [q.strip() for q in matches if len(q.strip()) > 5][:5]\n",
    "                    break\n",
    "            \n",
    "            # If no structured queries found, split by lines\n",
    "            if not queries:\n",
    "                lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "                queries = [line for line in lines if len(line) > 5 and '?' not in line][:3]\n",
    "            \n",
    "            # Ensure we have at least one query\n",
    "            if not queries:\n",
    "                queries = [\"basic information\"]\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing queries: {e}\")\n",
    "            queries = [\"basic information\"]\n",
    "        \n",
    "        return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathBuilder:\n",
    "    \"\"\"Builds learning paths using LLM intelligence and vector search\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzed_docs: List, vector_db_manager):\n",
    "        self.analyzed_docs = analyzed_docs\n",
    "        self.vector_db = vector_db_manager\n",
    "        self.module_discoverer = ModuleDiscoverer()\n",
    "        self.module_orderer = ModuleOrderer()\n",
    "        self.query_generator = QueryGenerator()  # Add this\n",
    "    \n",
    "    def _create_available_content_summary(self) -> str:\n",
    "        \"\"\"Create a brief summary of available content types\"\"\"\n",
    "        doc_types = {}\n",
    "        sample_topics = set()\n",
    "        \n",
    "        for doc in self.analyzed_docs:\n",
    "            doc_type = doc.classification.doc_type.value\n",
    "            doc_types[doc_type] = doc_types.get(doc_type, 0) + 1\n",
    "            \n",
    "            # Add some sample topics\n",
    "            if len(sample_topics) < 20:\n",
    "                sample_topics.add(doc.metadata.title or \"Untitled\")\n",
    "        \n",
    "        summary = f\"Available: {doc_types}. Sample topics: {', '.join(list(sample_topics)[:10])}\"\n",
    "        return summary\n",
    "    \n",
    "    def _search_content_for_module(self, module_title: str, difficulty_level: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Search for content related to a module using AI-generated queries\"\"\"\n",
    "        \n",
    "        content = {\n",
    "            \"tutorial\": [],\n",
    "            \"concept\": [],\n",
    "            \"example\": [],\n",
    "            \"reference\": []\n",
    "        }\n",
    "        \n",
    "        # Create overview of available content for query generation\n",
    "        available_content = self._create_available_content_summary()\n",
    "        \n",
    "        # Generate queries for each document type using LLM\n",
    "        for doc_type in content.keys():\n",
    "            logger.info(f\"Generating search queries for {module_title} - {doc_type} - {difficulty_level}\")\n",
    "            \n",
    "            try:\n",
    "                # Generate intelligent search queries\n",
    "                search_queries, reasoning = self.query_generator(\n",
    "                    module_title=module_title,\n",
    "                    difficulty_level=difficulty_level,\n",
    "                    doc_type=doc_type,\n",
    "                    available_content=available_content\n",
    "                )\n",
    "                \n",
    "                logger.info(f\"Generated queries for {doc_type}: {search_queries}\")\n",
    "                logger.info(f\"Reasoning: {reasoning}\")\n",
    "                \n",
    "                # Execute each generated query\n",
    "                for query in search_queries:\n",
    "                    try:\n",
    "                        results = self.vector_db.search(\n",
    "                            query=query,\n",
    "                            n_results=3,\n",
    "                            doc_types=[doc_type]\n",
    "                        )\n",
    "                        \n",
    "                        chunk_ids = [result.chunk.id for result in results]\n",
    "                        content[doc_type].extend(chunk_ids)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Search failed for '{query}' in {doc_type}: {e}\")\n",
    "                        continue\n",
    "                        \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Query generation failed for {module_title} - {doc_type}: {e}\")\n",
    "                # Fallback to simple query\n",
    "                try:\n",
    "                    results = self.vector_db.search(\n",
    "                        query=f\"{module_title} {doc_type}\",\n",
    "                        n_results=3,\n",
    "                        doc_types=[doc_type]\n",
    "                    )\n",
    "                    chunk_ids = [result.chunk.id for result in results]\n",
    "                    content[doc_type].extend(chunk_ids)\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Remove duplicates\n",
    "        for doc_type in content:\n",
    "            content[doc_type] = list(dict.fromkeys(content[doc_type]))  # Preserve order\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    # Rest of the methods remain the same...\n",
    "    def _create_rich_content_summary(self) -> str:\n",
    "        \"\"\"Create rich content summary with complete document information\"\"\"\n",
    "        \n",
    "        # Group documents by type for better organization\n",
    "        docs_by_type = {}\n",
    "        for doc in self.analyzed_docs:\n",
    "            doc_type = doc.classification.doc_type.value\n",
    "            if doc_type not in docs_by_type:\n",
    "                docs_by_type[doc_type] = []\n",
    "            docs_by_type[doc_type].append(doc)\n",
    "        \n",
    "        summary_text = f\"Available Documentation for Learning Path Creation:\\n\\n\"\n",
    "        summary_text += f\"Total Documents: {len(self.analyzed_docs)}\\n\\n\"\n",
    "        \n",
    "        # Add ALL documents organized by type - no limits\n",
    "        for doc_type, docs in docs_by_type.items():\n",
    "            summary_text += f\"{doc_type.upper()} DOCUMENTS ({len(docs)} total):\\n\"\n",
    "            \n",
    "            # Include ALL documents - no truncation\n",
    "            for i, doc in enumerate(docs):\n",
    "                doc_context = f\"\"\"  {i+1}. Title: {doc.metadata.title or 'Untitled'}\n",
    "     Headings: {', '.join(doc.metadata.headings)}\n",
    "     Summary: {doc.summary}\n",
    "\"\"\"\n",
    "                summary_text += doc_context\n",
    "            \n",
    "            summary_text += \"\\n\"\n",
    "        \n",
    "        return summary_text\n",
    "    \n",
    "    def _create_content_overview_for_ordering(self, modules: List[str]) -> str:\n",
    "        \"\"\"Create complete content overview for module ordering\"\"\"\n",
    "        \n",
    "        overview = f\"Content Overview for Module Ordering:\\n\\n\"\n",
    "        overview += f\"Proposed Modules: {', '.join(modules)}\\n\\n\"\n",
    "        \n",
    "        # For each proposed module, show ALL related content\n",
    "        for module in modules:\n",
    "            overview += f\"CONTENT AVAILABLE FOR '{module.upper()}':\\n\"\n",
    "            \n",
    "            # Find ALL documents that might relate to this module\n",
    "            related_docs = []\n",
    "            for doc in self.analyzed_docs:\n",
    "                # Check if module name appears in title, headings, or summary\n",
    "                search_text = f\"{doc.metadata.title} {' '.join(doc.metadata.headings)} {doc.summary}\".lower()\n",
    "                if (module.lower() in search_text or \n",
    "                    any(word in search_text for word in module.lower().split())):\n",
    "                    related_docs.append(doc)\n",
    "            \n",
    "            if related_docs:\n",
    "                # Include ALL related docs - no limits\n",
    "                for doc in related_docs:\n",
    "                    overview += f\"  - {doc.classification.doc_type.value}: {doc.metadata.title}\\n\"\n",
    "                    overview += f\"    Headings: {', '.join(doc.metadata.headings)}\\n\"\n",
    "                    overview += f\"    Summary: {doc.summary}\\n\"\n",
    "            else:\n",
    "                overview += f\"  - No directly related content found for this module\\n\"\n",
    "            \n",
    "            overview += \"\\n\"\n",
    "        \n",
    "        return overview\n",
    "    \n",
    "    def _estimate_module_time(self, content: Dict[str, List[str]]) -> int:\n",
    "        \"\"\"Estimate time for a module based on content\"\"\"\n",
    "        \n",
    "        time_estimates = {\n",
    "            \"tutorial\": 15,    # 15 minutes per tutorial chunk\n",
    "            \"concept\": 10,     # 10 minutes per concept chunk\n",
    "            \"example\": 8,      # 8 minutes per example chunk\n",
    "            \"reference\": 5     # 5 minutes per reference chunk\n",
    "        }\n",
    "        \n",
    "        total_time = 0\n",
    "        for doc_type, chunks in content.items():\n",
    "            total_time += len(chunks) * time_estimates.get(doc_type, 10)\n",
    "        \n",
    "        return max(total_time, 15)  # Minimum 15 minutes per module\n",
    "    \n",
    "    def _create_content_summary_for_module(self, content: Dict[str, List[str]]) -> str:\n",
    "        \"\"\"Create a summary of content found for a module\"\"\"\n",
    "        \n",
    "        summary_parts = []\n",
    "        for doc_type, chunks in content.items():\n",
    "            if chunks:\n",
    "                summary_parts.append(f\"{len(chunks)} {doc_type} chunks\")\n",
    "        \n",
    "        return \", \".join(summary_parts) if summary_parts else \"No content found\"\n",
    "    \n",
    "    def build_learning_path(self, \n",
    "                          module_headings: Optional[List[str]] = None,\n",
    "                          difficulty_level: str = \"intermediate\") -> LearningPath:\n",
    "        \"\"\"Build a complete learning path with AI-generated search queries\"\"\"\n",
    "        \n",
    "        logger.info(f\"Building learning path for difficulty: {difficulty_level}\")\n",
    "        \n",
    "        # Step 1: Create complete rich content summary\n",
    "        content_summary_text = self._create_rich_content_summary()\n",
    "        logger.info(f\"Created complete content summary with {len(self.analyzed_docs)} documents\")\n",
    "        \n",
    "        # Step 2: Discover modules\n",
    "        if module_headings:\n",
    "            modules = module_headings\n",
    "            discovery_reasoning = f\"Using user-provided modules: {', '.join(modules)}\"\n",
    "            logger.info(f\"Using provided modules: {modules}\")\n",
    "        else:\n",
    "            modules, discovery_reasoning = self.module_discoverer(\n",
    "                content_summary=content_summary_text,\n",
    "                difficulty_level=difficulty_level\n",
    "            )\n",
    "            logger.info(f\"Discovered modules: {modules}\")\n",
    "        \n",
    "        # Step 3: Create complete targeted overview for ordering\n",
    "        content_overview = self._create_content_overview_for_ordering(modules)\n",
    "        \n",
    "        # Step 4: Order modules\n",
    "        ordered_modules, ordering_reasoning = self.module_orderer(\n",
    "            modules=modules,\n",
    "            content_overview=content_overview,\n",
    "            difficulty_level=difficulty_level\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Ordered modules: {ordered_modules}\")\n",
    "        \n",
    "        # Step 5: Build learning modules with AI-generated queries\n",
    "        learning_modules = []\n",
    "        content_gaps = []\n",
    "        total_time = 0\n",
    "        \n",
    "        for module_title in ordered_modules:\n",
    "            logger.info(f\"Building content for module: {module_title}\")\n",
    "            \n",
    "            # Search for content using AI-generated queries\n",
    "            content = self._search_content_for_module(module_title, difficulty_level)\n",
    "            \n",
    "            # Check for content gaps\n",
    "            empty_types = [doc_type for doc_type, chunks in content.items() if not chunks]\n",
    "            if empty_types:\n",
    "                content_gaps.append(f\"Module '{module_title}' missing: {', '.join(empty_types)}\")\n",
    "            \n",
    "            # Calculate time\n",
    "            module_time = self._estimate_module_time(content)\n",
    "            total_time += module_time\n",
    "            \n",
    "            # Create learning module\n",
    "            learning_module = LearningModule(\n",
    "                title=module_title,\n",
    "                tutorial_content=content[\"tutorial\"],\n",
    "                concept_content=content[\"concept\"],\n",
    "                example_content=content[\"example\"],\n",
    "                reference_content=content[\"reference\"],\n",
    "                estimated_time=module_time,\n",
    "                content_summary=self._create_content_summary_for_module(content)\n",
    "            )\n",
    "            \n",
    "            learning_modules.append(learning_module)\n",
    "        \n",
    "        # Step 6: Create final learning path\n",
    "        learning_path = LearningPath(\n",
    "            modules=learning_modules,\n",
    "            difficulty_level=difficulty_level,\n",
    "            total_time=total_time,\n",
    "            module_count=len(learning_modules),\n",
    "            discovery_reasoning=discovery_reasoning,\n",
    "            ordering_reasoning=ordering_reasoning,\n",
    "            content_gaps=content_gaps\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Built learning path: {len(learning_modules)} modules, {total_time} minutes\")\n",
    "        return learning_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningPathManager:\n",
    "    \"\"\"High-level manager for learning path operations\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzed_docs: List, vector_db_manager):\n",
    "        self.path_builder = PathBuilder(analyzed_docs, vector_db_manager)\n",
    "    \n",
    "    def create_path(self, \n",
    "                   module_headings: Optional[List[str]] = None,\n",
    "                   difficulty_level: str = \"intermediate\") -> LearningPath:\n",
    "        \"\"\"Create a learning path\"\"\"\n",
    "        return self.path_builder.build_learning_path(module_headings, difficulty_level)\n",
    "    \n",
    "    def preview_available_content(self) -> ContentSummary:\n",
    "        \"\"\"Preview what content is available\"\"\"\n",
    "        return self.path_builder._create_content_summary()\n",
    "    \n",
    "    def test_module_content(self, module_title: str, difficulty_level: str = \"intermediate\") -> Dict:\n",
    "        \"\"\"Test what content would be found for a specific module\"\"\"\n",
    "        content = self.path_builder._search_content_for_module(module_title, difficulty_level)\n",
    "        \n",
    "        return {\n",
    "            \"module\": module_title,\n",
    "            \"difficulty\": difficulty_level,\n",
    "            \"content_found\": {doc_type: len(chunks) for doc_type, chunks in content.items()},\n",
    "            \"total_chunks\": sum(len(chunks) for chunks in content.values()),\n",
    "            \"estimated_time\": self.path_builder._estimate_module_time(content)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_manager = LearningPathManager(analyzed_docs, vector_db_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Building learning path for difficulty: beginner\n",
      "INFO:__main__:Created complete content summary with 14 documents\n",
      "INFO:__main__:Discovered modules: ['Understanding MCP Fundamentals', 'Core MCP Primitives: Resources, Prompts, and Tools', 'Defining Server Scope with Roots', 'Building Your First MCP Client', 'Building Your First MCP Server', 'Debugging and Testing MCP Integrations']\n",
      "INFO:__main__:Ordered modules: ['Understanding MCP Fundamentals', 'Core MCP Primitives: Resources, Prompts, and Tools', 'Defining Server Scope with Roots', 'Building Your First MCP Server', 'Building Your First MCP Client', 'Debugging and Testing MCP Integrations']\n",
      "INFO:__main__:Building content for module: Understanding MCP Fundamentals\n",
      "INFO:__main__:Generating search queries for Understanding MCP Fundamentals - tutorial - beginner\n",
      "INFO:__main__:Generated queries for tutorial: ['MCP fundamentals beginner tutorial', 'beginner tutorial MCP roots tools', 'how to create MCP project directory tutorial', 'MCP architecture transports beginner tutorial', 'getting started with MCP tutorial']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title's core terms (\"MCP Fundamentals\") with the specified difficulty (\"beginner\") and document type (\"tutorial\"). I've also incorporated specific, relevant keywords from the `available_content` such as \"roots,\" \"tools,\" \"architecture,\" and \"create project directory\" to make the queries more precise and target the foundational aspects suitable for a beginner tutorial.\n",
      "INFO:__main__:Generating search queries for Understanding MCP Fundamentals - concept - beginner\n",
      "INFO:__main__:Generated queries for concept: ['MCP fundamentals beginner concepts', 'beginner MCP architecture concepts', 'MCP roots and tools concepts for beginners', 'understanding MCP transports concept beginner', 'MCP inspector fundamental concepts']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title's core terms (\"MCP\", \"fundamentals\") with the target difficulty (\"beginner\") and document type (\"concept\"). I also incorporated specific fundamental topics identified from the `available_content` samples (e.g., \"architecture\", \"roots\", \"tools\", \"transports\", \"inspector\") to create more targeted queries for conceptual understanding at a beginner level.\n",
      "INFO:__main__:Generating search queries for Understanding MCP Fundamentals - example - beginner\n",
      "INFO:__main__:Generated queries for example: ['MCP fundamentals beginner example', 'How to create MCP project directory example', 'MCP basic tools usage example', 'MCP inspector simple demonstration', 'Beginner MCP setup example']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title \"Understanding MCP Fundamentals\" with the specified difficulty \"beginner\" and document type \"example\". I've incorporated specific, practical topics from the `available_content` like \"project directory\", \"tools\", and \"inspector\" to generate targeted queries. Terms like \"how to\", \"usage\", and \"demonstration\" are used to optimize for finding practical examples suitable for beginners. I also included a broader query to cover general fundamental examples.\n",
      "INFO:__main__:Generating search queries for Understanding MCP Fundamentals - reference - beginner\n",
      "INFO:__main__:Generated queries for reference: ['MCP fundamentals beginner reference', 'MCP architecture beginner reference guide', 'MCP tools beginner reference documentation', 'MCP transports beginner reference material', 'MCP inspector beginner reference']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the core module title \"MCP Fundamentals\" with the specified \"beginner\" difficulty and \"reference\" document type. I also incorporated specific fundamental topics identified from the `available_content` (e.g., architecture, tools, transports, inspector) to generate more targeted queries for reference material relevant to a beginner's understanding of MCP.\n",
      "INFO:__main__:Building content for module: Core MCP Primitives: Resources, Prompts, and Tools\n",
      "INFO:__main__:Generating search queries for Core MCP Primitives: Resources, Prompts, and Tools - tutorial - beginner\n",
      "INFO:__main__:Generated queries for tutorial: ['MCP primitives beginner tutorial', 'beginner tutorial MCP prompts', 'getting started with MCP tools tutorial', 'MCP resources tutorial for beginners']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module's core components (Resources, Prompts, Tools) with the specified difficulty (beginner) and document type (tutorial). Queries are designed to be specific enough to target relevant content while also including broader terms for introductory material. The available content topics like \"tools\" and \"prompts\" directly support these targeted queries.\n",
      "INFO:__main__:Generating search queries for Core MCP Primitives: Resources, Prompts, and Tools - concept - beginner\n",
      "INFO:__main__:Generated queries for concept: ['beginner concept MCP resources', 'introduction to MCP prompts', 'basic MCP tools explanation', 'what are core MCP primitives concepts', 'foundational MCP concepts for beginners']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on the core primitives mentioned in the module title (Resources, Prompts, Tools) combined with the specified difficulty level (beginner) and document type (concept). Queries are designed to find foundational explanations and introductions to these topics, leveraging keywords like \"what are,\" \"introduction,\" \"basic,\" and \"foundational\" to align with a beginner concept search.\n",
      "INFO:__main__:Generating search queries for Core MCP Primitives: Resources, Prompts, and Tools - example - beginner\n",
      "INFO:__main__:Generated queries for example: ['MCP prompts beginner example', 'MCP tools beginner example', 'Core MCP resources beginner example', 'Beginner example for MCP primitives', 'How to use MCP prompts and tools example']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the core components of the module title (Resources, Prompts, Tools, MCP Primitives) with the specified document type (example) and difficulty level (beginner). Queries are designed to be specific, targeting individual primitives for examples, and also broader to capture general beginner examples of MCP primitives. The available content hints like \"prompts\" and \"tools\" were directly incorporated.\n",
      "INFO:__main__:Generating search queries for Core MCP Primitives: Resources, Prompts, and Tools - reference - beginner\n",
      "INFO:__main__:Generated queries for reference: ['Core MCP primitives beginner reference guide', 'MCP resources definition and usage beginner reference', 'Basic concepts of MCP prompts reference for beginners', 'Overview of MCP tools for beginners reference', \"Beginner's reference to MCP primitives resources prompts tools\"]\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title's core components (\"MCP Primitives\", \"Resources\", \"Prompts\", \"Tools\") with the specified difficulty (\"beginner\") and document type (\"reference\"). Queries are designed to find foundational information, definitions, and overviews suitable for a beginner's reference guide. I've created a mix of general and specific queries to cover all aspects of the module.\n",
      "INFO:__main__:Building content for module: Defining Server Scope with Roots\n",
      "INFO:__main__:Generating search queries for Defining Server Scope with Roots - tutorial - beginner\n",
      "INFO:__main__:Generated queries for tutorial: ['beginner tutorial Defining Server Scope with Roots', 'how to define server scope with roots tutorial', 'roots server scope beginner guide', 'create project directory roots tutorial']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title, target difficulty, and document type to generate precise queries. Given the \"beginner\" difficulty and \"tutorial\" document type, queries include \"how to,\" \"guide,\" and \"step-by-step\" alongside core concepts like \"roots\" and \"server scope.\" The available content's mention of \"create project directory\" is also leveraged for practical, beginner-level tutorial queries.\n",
      "INFO:__main__:Generating search queries for Defining Server Scope with Roots - concept - beginner\n",
      "INFO:__main__:Generated queries for concept: ['beginner concept server scope roots', 'what is server scope and roots concept', 'defining server scope with roots beginner', 'introduction to server roots concept']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title's core terms (\"Server Scope\", \"Roots\") with the specified difficulty (\"beginner\") and document type (\"concept\"). Queries are designed to elicit fundamental explanations, definitions, and introductory material, aligning with a beginner-level conceptual understanding.\n",
      "INFO:__main__:Generating search queries for Defining Server Scope with Roots - example - beginner\n",
      "INFO:__main__:Generated queries for example: ['beginner example defining server scope roots', 'how to define server scope with roots tutorial example', 'roots server scope practical example', 'example of server scope definition using roots']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title's core concepts (\"server scope\", \"roots\") with the specified difficulty (\"beginner\") and document type (\"example\"). Given that 'example' isn't explicitly listed in `available_content` but 'tutorial' is, queries also include \"tutorial\" as tutorials often contain practical examples. Queries are designed to be direct and include terms like \"how to\" and \"practical\" to find hands-on demonstrations suitable for beginners.\n",
      "INFO:__main__:Generating search queries for Defining Server Scope with Roots - reference - beginner\n",
      "INFO:__main__:Generated queries for reference: ['roots reference', 'Defining Server Scope with Roots reference', 'server scope roots definition', 'beginner roots server scope reference']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the core concept \"roots\" with the specified document type \"reference\" and difficulty level \"beginner\". It also incorporates the full module title \"Defining Server Scope with Roots\" to ensure specificity. Queries are designed to find foundational information and definitions, which align with a \"reference\" document for a \"beginner\" audience.\n",
      "INFO:__main__:Building content for module: Building Your First MCP Server\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Server - tutorial - beginner\n",
      "INFO:__main__:Generated queries for tutorial: ['beginner tutorial building MCP server', 'how to set up your first MCP server', 'getting started with MCP server tutorial', 'step-by-step guide build MCP server', 'create MCP server project directory tutorial']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title, desired difficulty, and document type. For a \"beginner\" \"tutorial\" on \"Building Your First MCP Server\", queries will include terms like \"how to\", \"getting started\", \"setup\", and \"step-by-step guide\". Specific actions mentioned in the available content, such as \"create project directory\", are also incorporated to target relevant practical tutorials.\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Server - concept - beginner\n",
      "INFO:__main__:Generated queries for concept: ['Building MCP Server concepts beginner', 'Introduction to MCP Server architecture concepts', 'What is MCP Server basics for beginners', 'Foundational concepts of MCP Server development']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining keywords from the module title (\"Building Your First MCP Server\", \"MCP Server\"), the target difficulty (\"beginner\"), and the document type (\"concept\"). I will prioritize terms like \"introduction,\" \"basics,\" \"what is,\" and \"architecture\" (from sample topics) to find foundational conceptual information suitable for a beginner.\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Server - example - beginner\n",
      "INFO:__main__:Generated queries for example: ['Building Your First MCP Server example beginner', 'beginner MCP server setup step-by-step', 'how to create MCP server project directory example', 'first MCP server tutorial with practical examples']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title with the requested difficulty and document type. Since 'example' is not explicitly listed in available content types but 'tutorial' is, queries also include 'tutorial' as tutorials often contain practical examples. Keywords from the sample topics like \"project directory\" and \"setup\" are incorporated to make queries more specific and practical for a \"beginner\" \"example\" document.\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Server - reference - beginner\n",
      "INFO:__main__:Generated queries for reference: ['MCP server setup reference beginner', 'first MCP server architecture reference', 'MCP server initial configuration reference', 'MCP server project directory reference', 'MCP server tools reference beginner']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the core module topic \"MCP Server\" with keywords indicating \"beginner\" difficulty and \"reference\" document type. I've also incorporated terms from the `available_content` like \"project directory\" and \"tools\" that are highly relevant for setting up a first server and would typically be found in reference documentation. The queries aim to find foundational information, setup guides, and architectural overviews suitable for a beginner.\n",
      "INFO:__main__:Building content for module: Building Your First MCP Client\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Client - tutorial - beginner\n",
      "INFO:__main__:Generated queries for tutorial: ['Building Your First MCP Client tutorial beginner', 'MCP client setup tutorial for beginners', 'How to create MCP client project directory tutorial', 'Beginner tutorial build MCP client', 'Getting started with MCP client development tutorial']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title, desired difficulty, and document type to create highly relevant queries. I've also incorporated specific actions mentioned in the available content (like \"create project directory\") to target practical, step-by-step tutorials suitable for a beginner building their first client. Keywords like \"getting started\" and \"how to\" are used to emphasize the tutorial nature.\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Client - concept - beginner\n",
      "INFO:__main__:Generated queries for concept: ['MCP client architecture concept beginner', 'foundational concepts building first MCP client', 'beginner guide MCP client core concepts', 'understanding MCP client basics concept']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title's core terms (\"MCP Client\", \"first\", \"building\") with the desired document type (\"concept\") and difficulty level (\"beginner\"). Keywords from the `available_content` like \"architecture\", \"roots\", and \"tools\" are integrated to narrow down the search to relevant foundational concepts for a new user. The queries aim to find introductory explanations and core ideas rather than step-by-step instructions.\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Client - example - beginner\n",
      "INFO:__main__:Generated queries for example: ['Building Your First MCP Client example', 'beginner MCP client project example', 'MCP client setup example', 'example: Create project directory for MCP client', 'MCP client tools example for beginners']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title \"Building Your First MCP Client\" with the desired document type \"example\" and difficulty \"beginner\". I also incorporated specific keywords from the `available_content` like \"Create project directory\" and \"tools\" to generate highly relevant and actionable queries for a beginner-level example. While \"example\" isn't explicitly listed in the available content counts, tutorials often contain examples, making these queries useful for finding practical demonstrations.\n",
      "INFO:__main__:Generating search queries for Building Your First MCP Client - reference - beginner\n",
      "INFO:__main__:Generated queries for reference: ['Building Your First MCP Client beginner reference', 'MCP client project setup reference for beginners', 'MCP client architecture overview reference', 'MCP client development tools reference']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the module title, difficulty level, and document type to create broad initial queries. Subsequent queries narrow down to specific foundational aspects crucial for a beginner building their first client, such as project setup, core architecture, and necessary tools, aligning with the 'reference' document type and available content topics.\n",
      "INFO:__main__:Building content for module: Debugging and Testing MCP Integrations\n",
      "INFO:__main__:Generating search queries for Debugging and Testing MCP Integrations - tutorial - beginner\n",
      "INFO:__main__:Generated queries for tutorial: ['beginner tutorial debugging MCP integrations', 'step-by-step guide testing MCP integrations', 'how to debug MCP integrations tools tutorial', 'getting started with MCP integration testing tutorial']\n",
      "INFO:__main__:Reasoning: The search strategy focuses on combining the core module topic (\"Debugging and Testing MCP Integrations\") with the specified difficulty (\"beginner\") and document type (\"tutorial\"). Queries are designed to be \"how-to\" or \"getting started\" oriented, reflecting the beginner level and tutorial format. Keywords from the module title are prioritized, and relevant terms like \"tools\" are incorporated from the available content samples to make queries more specific.\n",
      "INFO:__main__:Generating search queries for Debugging and Testing MCP Integrations - concept - beginner\n"
     ]
    }
   ],
   "source": [
    "modules = path_manager.create_path(difficulty_level=\"beginner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Models for Generated Content\n",
    "class CodeExample(BaseModel):\n",
    "    \"\"\"A code example with explanation\"\"\"\n",
    "    title: str\n",
    "    code: str\n",
    "    language: str\n",
    "    explanation: str\n",
    "    difficulty_level: str\n",
    "\n",
    "class Exercise(BaseModel):\n",
    "    \"\"\"A practical exercise for learners\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    instructions: List[str]\n",
    "    hints: List[str] = Field(default_factory=list)\n",
    "    expected_outcome: str\n",
    "    difficulty_level: str\n",
    "\n",
    "class AssessmentQuestion(BaseModel):\n",
    "    \"\"\"An assessment question to test understanding\"\"\"\n",
    "    question: str\n",
    "    question_type: str  # multiple_choice, true_false, short_answer, code_completion\n",
    "    options: List[str] = Field(default_factory=list)  # For multiple choice\n",
    "    correct_answer: str\n",
    "    explanation: str\n",
    "    difficulty_level: str\n",
    "\n",
    "class LearningObjective(BaseModel):\n",
    "    \"\"\"A specific learning objective\"\"\"\n",
    "    objective: str\n",
    "    bloom_level: str  # remember, understand, apply, analyze, evaluate, create\n",
    "    measurable_outcome: str\n",
    "\n",
    "class GeneratedContent(BaseModel):\n",
    "    \"\"\"Complete generated content for a learning module\"\"\"\n",
    "    module_title: str\n",
    "    learning_objectives: List[LearningObjective]\n",
    "    lesson_text: str\n",
    "    code_examples: List[CodeExample]\n",
    "    exercises: List[Exercise]\n",
    "    assessment_questions: List[AssessmentQuestion]\n",
    "    estimated_time: int\n",
    "    prerequisites: List[str] = Field(default_factory=list)\n",
    "    key_concepts: List[str] = Field(default_factory=list)\n",
    "\n",
    "class ContentChunk(BaseModel):\n",
    "    \"\"\"Content chunk retrieved from vector DB\"\"\"\n",
    "    id: str\n",
    "    content: str\n",
    "    doc_type: str\n",
    "    title: str\n",
    "    metadata: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy Signatures\n",
    "class SynthesizeContent(dspy.Signature):\n",
    "    \"\"\"Synthesize multiple content chunks into a coherent learning lesson.\"\"\"\n",
    "    \n",
    "    module_title: str = dspy.InputField(desc=\"Title of the learning module\")\n",
    "    content_chunks: str = dspy.InputField(desc=\"Multiple content chunks to synthesize\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty level\")\n",
    "    bloom_level: str = dspy.InputField(desc=\"Bloom's taxonomy level to target\")\n",
    "    \n",
    "    lesson_text: str = dspy.OutputField(desc=\"Coherent lesson text that teaches the module concepts\")\n",
    "    key_concepts: List[str] = dspy.OutputField(desc=\"List of key concepts covered in the lesson\")\n",
    "\n",
    "class GenerateExercises(dspy.Signature):\n",
    "    \"\"\"Generate practical exercises from code examples and tutorials.\"\"\"\n",
    "    \n",
    "    module_title: str = dspy.InputField(desc=\"Title of the learning module\")\n",
    "    lesson_content: str = dspy.InputField(desc=\"The lesson content and examples\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty level\")\n",
    "    available_examples: str = dspy.InputField(desc=\"Available code examples and tutorials\")\n",
    "    \n",
    "    exercises: List[Exercise] = dspy.OutputField(desc=\"List of 2-4 practical exercises\")\n",
    "\n",
    "class CreateAssessment(dspy.Signature):\n",
    "    \"\"\"Create assessment questions to test understanding of concepts.\"\"\"\n",
    "    \n",
    "    module_title: str = dspy.InputField(desc=\"Title of the learning module\")\n",
    "    lesson_content: str = dspy.InputField(desc=\"The lesson content to assess\")\n",
    "    key_concepts: List[str] = dspy.InputField(desc=\"Key concepts to test\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty level\")\n",
    "    \n",
    "    assessment_questions: List[AssessmentQuestion] = dspy.OutputField(desc=\"List of 3-6 assessment questions\")\n",
    "\n",
    "class WriteLearningObjectives(dspy.Signature):\n",
    "    \"\"\"Write clear, measurable learning objectives for a module.\"\"\"\n",
    "    \n",
    "    module_title: str = dspy.InputField(desc=\"Title of the learning module\")\n",
    "    lesson_content: str = dspy.InputField(desc=\"The lesson content\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty level\")\n",
    "    bloom_level: str = dspy.InputField(desc=\"Target Bloom's taxonomy level\")\n",
    "    \n",
    "    learning_objectives: List[LearningObjective] = dspy.OutputField(desc=\"List of 3-5 clear learning objectives\")\n",
    "\n",
    "class ExtractCodeExamples(dspy.Signature):\n",
    "    \"\"\"Extract and enhance code examples from content chunks.\"\"\"\n",
    "    \n",
    "    module_title: str = dspy.InputField(desc=\"Title of the learning module\")\n",
    "    content_with_code: str = dspy.InputField(desc=\"Content chunks containing code examples\")\n",
    "    difficulty_level: str = dspy.InputField(desc=\"Target difficulty level\")\n",
    "    \n",
    "    code_examples: List[CodeExample] = dspy.OutputField(desc=\"List of enhanced code examples with explanations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fallback Parsers for Content Generation\n",
    "class ContentFallbackParser:\n",
    "    @staticmethod\n",
    "    def parse_exercises_response(response: str, module_title: str, difficulty_level: str) -> List[Exercise]:\n",
    "        \"\"\"Parse exercises from string response\"\"\"\n",
    "        exercises = []\n",
    "        \n",
    "        try:\n",
    "            # Look for exercise patterns\n",
    "            exercise_sections = re.split(r'(?:Exercise|EXERCISE)\\s*\\d*[:\\.]?\\s*', response)[1:]\n",
    "            \n",
    "            for i, section in enumerate(exercise_sections[:4]):  # Max 4 exercises\n",
    "                lines = [line.strip() for line in section.split('\\n') if line.strip()]\n",
    "                \n",
    "                if lines:\n",
    "                    title = lines[0].strip().strip('*-.')\n",
    "                    description = \"\"\n",
    "                    instructions = []\n",
    "                    \n",
    "                    # Parse description and instructions\n",
    "                    in_instructions = False\n",
    "                    for line in lines[1:]:\n",
    "                        if any(keyword in line.lower() for keyword in ['instruction', 'step', 'task', 'do:']):\n",
    "                            in_instructions = True\n",
    "                            continue\n",
    "                        \n",
    "                        if in_instructions:\n",
    "                            if line.startswith(('-', 'â€¢', '*')) or re.match(r'^\\d+\\.', line):\n",
    "                                instructions.append(line.strip('- â€¢*').strip())\n",
    "                        else:\n",
    "                            description += line + \" \"\n",
    "                    \n",
    "                    if not instructions:\n",
    "                        instructions = [description.strip()] if description.strip() else [f\"Practice {title}\"]\n",
    "                    \n",
    "                    exercises.append(Exercise(\n",
    "                        title=title if title else f\"Exercise {i+1}\",\n",
    "                        description=description.strip() or f\"Practice exercise for {module_title}\",\n",
    "                        instructions=instructions,\n",
    "                        expected_outcome=f\"Complete understanding of {module_title} concepts\",\n",
    "                        difficulty_level=difficulty_level\n",
    "                    ))\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing exercises: {e}\")\n",
    "        \n",
    "        if not exercises:\n",
    "            exercises = [Exercise(\n",
    "                title=f\"Practice {module_title}\",\n",
    "                description=f\"Complete a practical exercise on {module_title}\",\n",
    "                instructions=[f\"Apply the concepts learned in {module_title}\"],\n",
    "                expected_outcome=f\"Demonstrate understanding of {module_title}\",\n",
    "                difficulty_level=difficulty_level\n",
    "            )]\n",
    "        \n",
    "        return exercises\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_assessment_response(response: str, module_title: str, difficulty_level: str) -> List[AssessmentQuestion]:\n",
    "        \"\"\"Parse assessment questions from string response\"\"\"\n",
    "        questions = []\n",
    "        \n",
    "        try:\n",
    "            # Look for question patterns\n",
    "            question_sections = re.split(r'(?:Question|QUESTION)\\s*\\d*[:\\.]?\\s*', response)[1:]\n",
    "            \n",
    "            for i, section in enumerate(question_sections[:6]):  # Max 6 questions\n",
    "                lines = [line.strip() for line in section.split('\\n') if line.strip()]\n",
    "                \n",
    "                if lines:\n",
    "                    question_text = lines[0].strip()\n",
    "                    options = []\n",
    "                    correct_answer = \"\"\n",
    "                    explanation = \"\"\n",
    "                    \n",
    "                    # Parse options and answer\n",
    "                    for line in lines[1:]:\n",
    "                        if re.match(r'^[A-Da-d][\\.\\)]\\s*', line):\n",
    "                            options.append(line.strip())\n",
    "                        elif 'answer:' in line.lower() or 'correct:' in line.lower():\n",
    "                            correct_answer = line.split(':')[-1].strip()\n",
    "                        elif 'explanation:' in line.lower():\n",
    "                            explanation = line.split(':')[-1].strip()\n",
    "                    \n",
    "                    question_type = \"multiple_choice\" if options else \"short_answer\"\n",
    "                    \n",
    "                    questions.append(AssessmentQuestion(\n",
    "                        question=question_text,\n",
    "                        question_type=question_type,\n",
    "                        options=options,\n",
    "                        correct_answer=correct_answer or \"Sample answer\",\n",
    "                        explanation=explanation or f\"Tests understanding of {module_title}\",\n",
    "                        difficulty_level=difficulty_level\n",
    "                    ))\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing assessment: {e}\")\n",
    "        \n",
    "        if not questions:\n",
    "            questions = [AssessmentQuestion(\n",
    "                question=f\"What are the key concepts of {module_title}?\",\n",
    "                question_type=\"short_answer\",\n",
    "                correct_answer=f\"Key concepts of {module_title}\",\n",
    "                explanation=f\"Tests basic understanding of {module_title}\",\n",
    "                difficulty_level=difficulty_level\n",
    "            )]\n",
    "        \n",
    "        return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentSynthesizer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.synthesize = dspy.ChainOfThought(SynthesizeContent)\n",
    "    \n",
    "    def forward(self, module_title: str, content_chunks: List[ContentChunk], \n",
    "                difficulty_level: str, bloom_level: str = \"understand\"):\n",
    "        try:\n",
    "            # Limit content to avoid token limits\n",
    "            chunks_text = \"\\n\\n\".join([\n",
    "                f\"[{chunk.doc_type.upper()}] {chunk.title}:\\n{chunk.content[:500]}...\"  # Limit each chunk\n",
    "                for chunk in content_chunks[:5]  # Limit number of chunks\n",
    "            ])\n",
    "            \n",
    "            result = self.synthesize(\n",
    "                module_title=module_title,\n",
    "                content_chunks=chunks_text,\n",
    "                difficulty_level=difficulty_level,\n",
    "                bloom_level=bloom_level\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, 'lesson_text') and hasattr(result, 'key_concepts'):\n",
    "                lesson_text = str(result.lesson_text) if result.lesson_text else f\"Learning content for {module_title}\"\n",
    "                key_concepts = result.key_concepts if result.key_concepts else [module_title]\n",
    "                \n",
    "                if isinstance(key_concepts, str):\n",
    "                    key_concepts = [c.strip() for c in key_concepts.split(',') if c.strip()]\n",
    "                \n",
    "                return lesson_text, key_concepts\n",
    "            else:\n",
    "                response_str = str(result) if result else f\"Learning content for {module_title}\"\n",
    "                return response_str, [module_title]\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in content synthesis: {e}\")\n",
    "            return f\"Learning content for {module_title}. This module covers important concepts related to {module_title}.\", [module_title]\n",
    "\n",
    "class ExerciseGenerator(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate = dspy.ChainOfThought(GenerateExercises)\n",
    "    \n",
    "    def forward(self, module_title: str, lesson_content: str, \n",
    "                difficulty_level: str, available_examples: str):\n",
    "        try:\n",
    "            result = self.generate(\n",
    "                module_title=module_title,\n",
    "                lesson_content=lesson_content[:1500],  # Limit for token efficiency\n",
    "                difficulty_level=difficulty_level,\n",
    "                available_examples=available_examples[:1000]  # Limit examples too\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, 'exercises') and result.exercises is not None:\n",
    "                exercises = result.exercises\n",
    "                \n",
    "                if isinstance(exercises, str):\n",
    "                    exercises = ContentFallbackParser.parse_exercises_response(\n",
    "                        exercises, module_title, difficulty_level\n",
    "                    )\n",
    "                elif not isinstance(exercises, list):\n",
    "                    exercises = []\n",
    "                \n",
    "                return exercises if exercises else self._create_fallback_exercise(module_title, difficulty_level)\n",
    "            else:\n",
    "                response_str = str(result) if result else \"\"\n",
    "                parsed = ContentFallbackParser.parse_exercises_response(\n",
    "                    response_str, module_title, difficulty_level\n",
    "                )\n",
    "                return parsed if parsed else self._create_fallback_exercise(module_title, difficulty_level)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating exercises: {e}\")\n",
    "            return self._create_fallback_exercise(module_title, difficulty_level)\n",
    "    \n",
    "    def _create_fallback_exercise(self, module_title: str, difficulty_level: str) -> List[Exercise]:\n",
    "        \"\"\"Create fallback exercise when generation fails\"\"\"\n",
    "        return [Exercise(\n",
    "            title=f\"Practice {module_title}\",\n",
    "            description=f\"Apply the concepts learned in {module_title}\",\n",
    "            instructions=[\n",
    "                f\"Review the key concepts of {module_title}\",\n",
    "                f\"Try implementing a simple example\",\n",
    "                f\"Test your understanding with practical application\"\n",
    "            ],\n",
    "            expected_outcome=f\"Demonstrate understanding of {module_title} concepts\",\n",
    "            difficulty_level=difficulty_level\n",
    "        )]\n",
    "\n",
    "class AssessmentCreator(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.create = dspy.ChainOfThought(CreateAssessment)\n",
    "    \n",
    "    def forward(self, module_title: str, lesson_content: str, \n",
    "                key_concepts: List[str], difficulty_level: str):\n",
    "        try:\n",
    "            result = self.create(\n",
    "                module_title=module_title,\n",
    "                lesson_content=lesson_content[:1500],\n",
    "                key_concepts=key_concepts[:5],  # Limit concepts\n",
    "                difficulty_level=difficulty_level\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, 'assessment_questions') and result.assessment_questions is not None:\n",
    "                questions = result.assessment_questions\n",
    "                \n",
    "                if isinstance(questions, str):\n",
    "                    questions = ContentFallbackParser.parse_assessment_response(\n",
    "                        questions, module_title, difficulty_level\n",
    "                    )\n",
    "                elif not isinstance(questions, list):\n",
    "                    questions = []\n",
    "                \n",
    "                return questions if questions else self._create_fallback_assessment(module_title, difficulty_level)\n",
    "            else:\n",
    "                response_str = str(result) if result else \"\"\n",
    "                parsed = ContentFallbackParser.parse_assessment_response(\n",
    "                    response_str, module_title, difficulty_level\n",
    "                )\n",
    "                return parsed if parsed else self._create_fallback_assessment(module_title, difficulty_level)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating assessment: {e}\")\n",
    "            return self._create_fallback_assessment(module_title, difficulty_level)\n",
    "    \n",
    "    def _create_fallback_assessment(self, module_title: str, difficulty_level: str) -> List[AssessmentQuestion]:\n",
    "        \"\"\"Create fallback assessment when generation fails\"\"\"\n",
    "        return [\n",
    "            AssessmentQuestion(\n",
    "                question=f\"What are the main concepts of {module_title}?\",\n",
    "                question_type=\"short_answer\",\n",
    "                correct_answer=f\"The main concepts include the core principles and applications of {module_title}\",\n",
    "                explanation=f\"Tests basic understanding of {module_title}\",\n",
    "                difficulty_level=difficulty_level\n",
    "            ),\n",
    "            AssessmentQuestion(\n",
    "                question=f\"How would you apply {module_title} in practice?\",\n",
    "                question_type=\"short_answer\",\n",
    "                correct_answer=f\"Practical application involves implementing {module_title} concepts in real scenarios\",\n",
    "                explanation=f\"Tests practical application skills\",\n",
    "                difficulty_level=difficulty_level\n",
    "            )\n",
    "        ]\n",
    "\n",
    "class ObjectiveWriter(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.write = dspy.ChainOfThought(WriteLearningObjectives)\n",
    "    \n",
    "    def forward(self, module_title: str, lesson_content: str, \n",
    "                difficulty_level: str, bloom_level: str = \"understand\"):\n",
    "        try:\n",
    "            result = self.write(\n",
    "                module_title=module_title,\n",
    "                lesson_content=lesson_content[:1500],\n",
    "                difficulty_level=difficulty_level,\n",
    "                bloom_level=bloom_level\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, 'learning_objectives') and result.learning_objectives is not None:\n",
    "                objectives = result.learning_objectives\n",
    "                \n",
    "                if isinstance(objectives, str):\n",
    "                    obj_lines = [line.strip() for line in objectives.split('\\n') if line.strip()]\n",
    "                    objectives = [\n",
    "                        LearningObjective(\n",
    "                            objective=line.strip('- â€¢*'),\n",
    "                            bloom_level=bloom_level,\n",
    "                            measurable_outcome=f\"Demonstrate {bloom_level} of {module_title}\"\n",
    "                        )\n",
    "                        for line in obj_lines[:5] if len(line.strip()) > 10\n",
    "                    ]\n",
    "                elif not isinstance(objectives, list):\n",
    "                    objectives = []\n",
    "                \n",
    "                return objectives if objectives else self._create_fallback_objectives(module_title, bloom_level)\n",
    "            else:\n",
    "                return self._create_fallback_objectives(module_title, bloom_level)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error writing objectives: {e}\")\n",
    "            return self._create_fallback_objectives(module_title, bloom_level)\n",
    "    \n",
    "    def _create_fallback_objectives(self, module_title: str, bloom_level: str) -> List[LearningObjective]:\n",
    "        \"\"\"Create fallback objectives when generation fails\"\"\"\n",
    "        return [\n",
    "            LearningObjective(\n",
    "                objective=f\"Understand the core concepts of {module_title}\",\n",
    "                bloom_level=bloom_level,\n",
    "                measurable_outcome=f\"Explain the key principles of {module_title}\"\n",
    "            ),\n",
    "            LearningObjective(\n",
    "                objective=f\"Apply {module_title} in practical scenarios\",\n",
    "                bloom_level=\"apply\",\n",
    "                measurable_outcome=f\"Implement {module_title} concepts in real-world examples\"\n",
    "            )\n",
    "        ]\n",
    "\n",
    "class CodeExampleExtractor(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.extract = dspy.ChainOfThought(ExtractCodeExamples)\n",
    "    \n",
    "    def forward(self, module_title: str, content_with_code: str, difficulty_level: str):\n",
    "        try:\n",
    "            # Limit content to avoid token issues\n",
    "            limited_content = content_with_code[:2000] if content_with_code else \"\"\n",
    "            \n",
    "            result = self.extract(\n",
    "                module_title=module_title,\n",
    "                content_with_code=limited_content,\n",
    "                difficulty_level=difficulty_level\n",
    "            )\n",
    "            \n",
    "            if hasattr(result, 'code_examples') and result.code_examples is not None:\n",
    "                examples = result.code_examples\n",
    "                \n",
    "                if isinstance(examples, str):\n",
    "                    examples = self._extract_code_from_string(examples, module_title, difficulty_level)\n",
    "                elif not isinstance(examples, list):\n",
    "                    examples = []\n",
    "                \n",
    "                return examples if examples else []\n",
    "            else:\n",
    "                response_str = str(result) if result else \"\"\n",
    "                return self._extract_code_from_string(response_str, module_title, difficulty_level)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting code examples: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_code_from_string(self, content: str, module_title: str, difficulty_level: str) -> List[CodeExample]:\n",
    "        \"\"\"Extract code examples from string content\"\"\"\n",
    "        examples = []\n",
    "        \n",
    "        try:\n",
    "            # Look for code blocks\n",
    "            code_blocks = re.findall(r'```(\\w+)?\\n(.*?)\\n```', content, re.DOTALL)\n",
    "            \n",
    "            for i, (lang, code) in enumerate(code_blocks[:3]):  # Max 3 examples\n",
    "                if code.strip():\n",
    "                    examples.append(CodeExample(\n",
    "                        title=f\"{module_title} Example {i+1}\",\n",
    "                        code=code.strip(),\n",
    "                        language=lang.lower() if lang else 'text',\n",
    "                        explanation=f\"This example demonstrates {module_title} concepts\",\n",
    "                        difficulty_level=difficulty_level\n",
    "                    ))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error parsing code examples: {e}\")\n",
    "        \n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Content Generator\n",
    "class ContentGenerator:\n",
    "    \"\"\"Generates complete learning content from learning modules\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_db_manager):\n",
    "        self.vector_db = vector_db_manager\n",
    "        self.content_synthesizer = ContentSynthesizer()\n",
    "        self.exercise_generator = ExerciseGenerator()\n",
    "        self.assessment_creator = AssessmentCreator()\n",
    "        self.objective_writer = ObjectiveWriter()\n",
    "        self.code_extractor = CodeExampleExtractor()\n",
    "    \n",
    "    def _retrieve_content_chunks(self, chunk_ids: List[str]) -> List[ContentChunk]:\n",
    "        \"\"\"Retrieve actual content from chunk IDs\"\"\"\n",
    "        chunks = []\n",
    "        \n",
    "        for chunk_id in chunk_ids[:10]:  # Limit to 10 chunks to avoid token issues\n",
    "            try:\n",
    "                results = self.vector_db.vector_db.collection.get(ids=[chunk_id])\n",
    "                \n",
    "                if results['ids']:\n",
    "                    chunk = ContentChunk(\n",
    "                        id=chunk_id,\n",
    "                        content=results['documents'][0],\n",
    "                        doc_type=results['metadatas'][0].get('doc_type', 'unknown'),\n",
    "                        title=results['metadatas'][0].get('title', 'Untitled'),\n",
    "                        metadata=results['metadatas'][0]\n",
    "                    )\n",
    "                    chunks.append(chunk)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not retrieve chunk {chunk_id}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def generate_content(self, \n",
    "                        learning_module, \n",
    "                        difficulty_level: str = \"intermediate\",\n",
    "                        bloom_level: str = \"understand\") -> GeneratedContent:\n",
    "        \"\"\"Generate complete learning content for a module\"\"\"\n",
    "        \n",
    "        logger.info(f\"Generating content for module: {learning_module.title}\")\n",
    "        \n",
    "        # Step 1: Retrieve content chunks (limit to avoid token issues)\n",
    "        all_chunk_ids = (\n",
    "            learning_module.tutorial_content[:5] +\n",
    "            learning_module.concept_content[:5] +\n",
    "            learning_module.example_content[:3] +\n",
    "            learning_module.reference_content[:3]\n",
    "        )\n",
    "        \n",
    "        content_chunks = self._retrieve_content_chunks(all_chunk_ids)\n",
    "        logger.info(f\"Retrieved {len(content_chunks)} content chunks\")\n",
    "        \n",
    "        # Initialize with defaults to avoid validation errors\n",
    "        lesson_text = f\"Learning content for {learning_module.title}\"\n",
    "        key_concepts = [learning_module.title]\n",
    "        code_examples = []\n",
    "        exercises = []\n",
    "        assessment_questions = []\n",
    "        learning_objectives = []\n",
    "        \n",
    "        if content_chunks:\n",
    "            try:\n",
    "                # Step 2: Synthesize main lesson content\n",
    "                lesson_text, key_concepts = self.content_synthesizer(\n",
    "                    module_title=learning_module.title,\n",
    "                    content_chunks=content_chunks,\n",
    "                    difficulty_level=difficulty_level,\n",
    "                    bloom_level=bloom_level\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in content synthesis: {e}\")\n",
    "            \n",
    "            try:\n",
    "                # Step 3: Extract code examples\n",
    "                code_content = \"\\n\\n\".join([\n",
    "                    chunk.content[:500] for chunk in content_chunks \n",
    "                    if '```' in chunk.content or chunk.doc_type in ['tutorial', 'example']\n",
    "                ][:3])  # Limit content\n",
    "                \n",
    "                if code_content:\n",
    "                    code_examples = self.code_extractor(\n",
    "                        module_title=learning_module.title,\n",
    "                        content_with_code=code_content,\n",
    "                        difficulty_level=difficulty_level\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error extracting code examples: {e}\")\n",
    "                code_examples = []\n",
    "            \n",
    "            try:\n",
    "                # Step 4: Generate exercises\n",
    "                example_content = \"\\n\\n\".join([\n",
    "                    chunk.content[:400] for chunk in content_chunks\n",
    "                    if chunk.doc_type in ['tutorial', 'example']\n",
    "                ][:3])\n",
    "                \n",
    "                exercises = self.exercise_generator(\n",
    "                    module_title=learning_module.title,\n",
    "                    lesson_content=lesson_text,\n",
    "                    difficulty_level=difficulty_level,\n",
    "                    available_examples=example_content\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error generating exercises: {e}\")\n",
    "                exercises = []\n",
    "            \n",
    "            try:\n",
    "                # Step 5: Create assessment questions\n",
    "                assessment_questions = self.assessment_creator(\n",
    "                    module_title=learning_module.title,\n",
    "                    lesson_content=lesson_text,\n",
    "                    key_concepts=key_concepts,\n",
    "                    difficulty_level=difficulty_level\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error creating assessment: {e}\")\n",
    "                assessment_questions = []\n",
    "            \n",
    "            try:\n",
    "                # Step 6: Write learning objectives\n",
    "                learning_objectives = self.objective_writer(\n",
    "                    module_title=learning_module.title,\n",
    "                    lesson_content=lesson_text,\n",
    "                    difficulty_level=difficulty_level,\n",
    "                    bloom_level=bloom_level\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error writing objectives: {e}\")\n",
    "                learning_objectives = []\n",
    "        \n",
    "        # Ensure all fields have valid defaults\n",
    "        generated_content = GeneratedContent(\n",
    "            module_title=learning_module.title,\n",
    "            learning_objectives=learning_objectives or [],\n",
    "            lesson_text=lesson_text,\n",
    "            code_examples=code_examples or [],\n",
    "            exercises=exercises or [],\n",
    "            assessment_questions=assessment_questions or [],\n",
    "            estimated_time=learning_module.estimated_time,\n",
    "            key_concepts=key_concepts or []\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Generated content for {learning_module.title}: \"\n",
    "                   f\"{len(code_examples)} examples, {len(exercises)} exercises, \"\n",
    "                   f\"{len(assessment_questions)} questions\")\n",
    "        \n",
    "        return generated_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Manager\n",
    "class ContentGenerationManager:\n",
    "    \"\"\"High-level manager for content generation\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_db_manager):\n",
    "        self.content_generator = ContentGenerator(vector_db_manager)\n",
    "    \n",
    "    def generate_course_content(self, \n",
    "                               learning_path, \n",
    "                               difficulty_level: str = \"intermediate\") -> List[GeneratedContent]:\n",
    "        \"\"\"Generate content for an entire learning path\"\"\"\n",
    "        \n",
    "        generated_modules = []\n",
    "        \n",
    "        for module in learning_path.modules:\n",
    "            try:\n",
    "                generated_content = self.content_generator.generate_content(\n",
    "                    learning_module=module,\n",
    "                    difficulty_level=difficulty_level\n",
    "                )\n",
    "                generated_modules.append(generated_content)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error generating content for {module.title}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return generated_modules\n",
    "    \n",
    "    def generate_single_module_content(self, \n",
    "                                     learning_module, \n",
    "                                     difficulty_level: str = \"intermediate\",\n",
    "                                     bloom_level: str = \"understand\") -> GeneratedContent:\n",
    "        \"\"\"Generate content for a single module\"\"\"\n",
    "        \n",
    "        return self.content_generator.generate_content(\n",
    "            learning_module=learning_module,\n",
    "            difficulty_level=difficulty_level,\n",
    "            bloom_level=bloom_level\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize content generation\n",
    "content_manager = ContentGenerationManager(vector_db_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate content for entire learning path\n",
    "generated_course = content_manager.generate_course_content(\n",
    "    learning_path=modules,\n",
    "    difficulty_level=\"intermediate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Or generate content for a single module\n",
    "# single_module_content = content_manager.generate_single_module_content(\n",
    "#     learning_module=learning_path.modules[0],\n",
    "#     difficulty_level=\"intermediate\",\n",
    "#     bloom_level=\"apply\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
